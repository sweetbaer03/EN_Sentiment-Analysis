{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "friends_electra_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sweetbaer03/EN_Sentiment-Analysis/blob/main/friends_electra_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAQZkw3GC_SR"
      },
      "source": [
        "**FRIENDS Sentiment Analysis**\r\n",
        "\r\n",
        "\r\n",
        "electra 모델 사용 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6L4cQQhK5Ct0",
        "outputId": "fdea011f-e3e7-483c-f43f-b16c18fce9d3"
      },
      "source": [
        "#transformers 설치(colab 사용시)\r\n",
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/db/98c3ea1a78190dac41c0127a063abf92bd01b4b0b6970a6db1c2f5b66fa0/transformers-4.0.1-py3-none-any.whl (1.4MB)\n",
            "\r\u001b[K     |▎                               | 10kB 16.6MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 22.9MB/s eta 0:00:01\r\u001b[K     |▊                               | 30kB 25.7MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 19.6MB/s eta 0:00:01\r\u001b[K     |█▏                              | 51kB 17.0MB/s eta 0:00:01\r\u001b[K     |█▌                              | 61kB 18.9MB/s eta 0:00:01\r\u001b[K     |█▊                              | 71kB 15.9MB/s eta 0:00:01\r\u001b[K     |██                              | 81kB 13.8MB/s eta 0:00:01\r\u001b[K     |██▏                             | 92kB 13.5MB/s eta 0:00:01\r\u001b[K     |██▍                             | 102kB 12.9MB/s eta 0:00:01\r\u001b[K     |██▋                             | 112kB 12.9MB/s eta 0:00:01\r\u001b[K     |███                             | 122kB 12.9MB/s eta 0:00:01\r\u001b[K     |███▏                            | 133kB 12.9MB/s eta 0:00:01\r\u001b[K     |███▍                            | 143kB 12.9MB/s eta 0:00:01\r\u001b[K     |███▋                            | 153kB 12.9MB/s eta 0:00:01\r\u001b[K     |███▉                            | 163kB 12.9MB/s eta 0:00:01\r\u001b[K     |████▏                           | 174kB 12.9MB/s eta 0:00:01\r\u001b[K     |████▍                           | 184kB 12.9MB/s eta 0:00:01\r\u001b[K     |████▋                           | 194kB 12.9MB/s eta 0:00:01\r\u001b[K     |████▉                           | 204kB 12.9MB/s eta 0:00:01\r\u001b[K     |█████                           | 215kB 12.9MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 225kB 12.9MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 235kB 12.9MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 245kB 12.9MB/s eta 0:00:01\r\u001b[K     |██████                          | 256kB 12.9MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 266kB 12.9MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 276kB 12.9MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 286kB 12.9MB/s eta 0:00:01\r\u001b[K     |███████                         | 296kB 12.9MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 307kB 12.9MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 317kB 12.9MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 327kB 12.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 337kB 12.9MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 348kB 12.9MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 358kB 12.9MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 368kB 12.9MB/s eta 0:00:01\r\u001b[K     |█████████                       | 378kB 12.9MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 389kB 12.9MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 399kB 12.9MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 409kB 12.9MB/s eta 0:00:01\r\u001b[K     |██████████                      | 419kB 12.9MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 430kB 12.9MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 440kB 12.9MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 450kB 12.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 460kB 12.9MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 471kB 12.9MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 481kB 12.9MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 491kB 12.9MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 501kB 12.9MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 512kB 12.9MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 522kB 12.9MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 532kB 12.9MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 542kB 12.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 552kB 12.9MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 563kB 12.9MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 573kB 12.9MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 583kB 12.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 593kB 12.9MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 604kB 12.9MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 614kB 12.9MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 624kB 12.9MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 634kB 12.9MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 645kB 12.9MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 655kB 12.9MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 665kB 12.9MB/s eta 0:00:01\r\u001b[K     |████████████████                | 675kB 12.9MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 686kB 12.9MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 696kB 12.9MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 706kB 12.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 716kB 12.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 727kB 12.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 737kB 12.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 747kB 12.9MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 757kB 12.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 768kB 12.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 778kB 12.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 788kB 12.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 798kB 12.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 808kB 12.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 819kB 12.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 829kB 12.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 839kB 12.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 849kB 12.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 860kB 12.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 870kB 12.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 880kB 12.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 890kB 12.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 901kB 12.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 911kB 12.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 921kB 12.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 931kB 12.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 942kB 12.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 952kB 12.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 962kB 12.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 972kB 12.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 983kB 12.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 993kB 12.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.0MB 12.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.0MB 12.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.0MB 12.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.0MB 12.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.0MB 12.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.1MB 12.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.1MB 12.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.1MB 12.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.1MB 12.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.1MB 12.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.1MB 12.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.1MB 12.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.1MB 12.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.1MB 12.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.1MB 12.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.2MB 12.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.2MB 12.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.2MB 12.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.2MB 12.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.2MB 12.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.2MB 12.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.2MB 12.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.2MB 12.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.2MB 12.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.2MB 12.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.3MB 12.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.3MB 12.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.3MB 12.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.3MB 12.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.3MB 12.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.3MB 12.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.3MB 12.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.3MB 12.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.3MB 12.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.4MB 12.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.4MB 12.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.7)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 45.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 45.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=23404bea414a17e4a275d5b6878403b0d539763fba7d72394e21cdbe0ecec791\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruNN11LG5X4u"
      },
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import datetime\n",
        "import json\n",
        "import re\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from transformers import ElectraTokenizer, ElectraForSequenceClassification\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKyellxTJ2x8"
      },
      "source": [
        "# 데이터처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4_k4ixtDh9a"
      },
      "source": [
        "github에서 필요한 데이터파일 다운"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sb0Kgtz3G4E_",
        "outputId": "7d9722bd-d9a9-41b5-eae1-81dfaa30f9df"
      },
      "source": [
        "!git clone https://github.com/sweetbaer03/EN_Sentiment-Analysis.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'EN_Sentiment-Analysis'...\n",
            "remote: Enumerating objects: 11, done.\u001b[K\n",
            "remote: Counting objects: 100% (11/11), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 11 (delta 1), reused 8 (delta 1), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (11/11), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYQ6N4w5K5UY"
      },
      "source": [
        "MAX_LEN = 128 \r\n",
        "batch_size = 32\r\n",
        "epochs = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDfjgabiJ78m"
      },
      "source": [
        "## 1.1 프렌즈 / 캐글 테스트 데이터"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqhtjsOgL1vg"
      },
      "source": [
        "프렌즈 데이터"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-0roV-569a3"
      },
      "source": [
        "def jsonToDf(file_name):\n",
        "  with open(file_name, encoding = 'utf-8', mode = 'r') as file:\n",
        "    json_array = json.load(file)\n",
        "  \n",
        "  result = pd.DataFrame.from_dict(json_array[0])\n",
        "\n",
        "  is_first = True\n",
        "  for array in json_array:\n",
        "    if is_first:\n",
        "      is_first = False\n",
        "      continue\n",
        "    \n",
        "    temp_df = pd.DataFrame.from_dict(array)\n",
        "    result = result.append(temp_df, ignore_index = True)\n",
        "\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6egFjJ48qzG"
      },
      "source": [
        "train_data = jsonToDf('EN_Sentiment-Analysis/data_in/friends_train.json')\n",
        "dev_data   = jsonToDf('EN_Sentiment-Analysis/data_in/friends_dev.json')\n",
        "test_data  = jsonToDf('EN_Sentiment-Analysis/data_in/friends_test.json')\n",
        "\n",
        "#train = train.append(dev, ignore_index = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "OmAGtunpwrGo",
        "outputId": "c0247652-6626-404f-ef26-34a469594d89"
      },
      "source": [
        "train_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>speaker</th>\n",
              "      <th>utterance</th>\n",
              "      <th>emotion</th>\n",
              "      <th>annotation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Chandler</td>\n",
              "      <td>also I was the point person on my companys tr...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The Interviewer</td>\n",
              "      <td>You mustve had your hands full.</td>\n",
              "      <td>neutral</td>\n",
              "      <td>5000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Chandler</td>\n",
              "      <td>That I did. That I did.</td>\n",
              "      <td>neutral</td>\n",
              "      <td>5000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The Interviewer</td>\n",
              "      <td>So lets talk a little bit about your duties.</td>\n",
              "      <td>neutral</td>\n",
              "      <td>5000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Chandler</td>\n",
              "      <td>My duties?  All right.</td>\n",
              "      <td>surprise</td>\n",
              "      <td>2000030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10556</th>\n",
              "      <td>Chandler</td>\n",
              "      <td>You or me?</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3000011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10557</th>\n",
              "      <td>Ross</td>\n",
              "      <td>I got it. Uh, Joey, women don't have Adam's ap...</td>\n",
              "      <td>non-neutral</td>\n",
              "      <td>2100011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10558</th>\n",
              "      <td>Joey</td>\n",
              "      <td>You guys are messing with me, right?</td>\n",
              "      <td>surprise</td>\n",
              "      <td>0000050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10559</th>\n",
              "      <td>All</td>\n",
              "      <td>Yeah.</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4000010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10560</th>\n",
              "      <td>Joey</td>\n",
              "      <td>That was a good one. For a second there, I was...</td>\n",
              "      <td>non-neutral</td>\n",
              "      <td>1200020</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10561 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               speaker  ... annotation\n",
              "0             Chandler  ...    4100000\n",
              "1      The Interviewer  ...    5000000\n",
              "2             Chandler  ...    5000000\n",
              "3      The Interviewer  ...    5000000\n",
              "4             Chandler  ...    2000030\n",
              "...                ...  ...        ...\n",
              "10556         Chandler  ...    3000011\n",
              "10557             Ross  ...    2100011\n",
              "10558             Joey  ...    0000050\n",
              "10559              All  ...    4000010\n",
              "10560             Joey  ...    1200020\n",
              "\n",
              "[10561 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "niqFH_2CwrUl",
        "outputId": "e43b8e32-1084-4066-e265-f1429a09de46"
      },
      "source": [
        "dev_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>speaker</th>\n",
              "      <th>utterance</th>\n",
              "      <th>emotion</th>\n",
              "      <th>annotation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Phoebe</td>\n",
              "      <td>Oh my God, hes lost it. Hes totally lost it.</td>\n",
              "      <td>non-neutral</td>\n",
              "      <td>0002120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Monica</td>\n",
              "      <td>What?</td>\n",
              "      <td>surprise</td>\n",
              "      <td>1000130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ross</td>\n",
              "      <td>Or! Or, we could go to the bank, close our acc...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Chandler</td>\n",
              "      <td>Youre a genius!</td>\n",
              "      <td>joy</td>\n",
              "      <td>0500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Joey</td>\n",
              "      <td>Aww, man, now we wont be bank buddies!</td>\n",
              "      <td>sadness</td>\n",
              "      <td>0040100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1173</th>\n",
              "      <td>Monica</td>\n",
              "      <td>No.</td>\n",
              "      <td>sadness</td>\n",
              "      <td>2030000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1174</th>\n",
              "      <td>Rachel</td>\n",
              "      <td>What? Oh my God! Im gonna miss you so much!</td>\n",
              "      <td>sadness</td>\n",
              "      <td>0040010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1175</th>\n",
              "      <td>Monica</td>\n",
              "      <td>Im gonna miss you!</td>\n",
              "      <td>sadness</td>\n",
              "      <td>0050000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1176</th>\n",
              "      <td>Rachel</td>\n",
              "      <td>I mean its the end of an era!</td>\n",
              "      <td>sadness</td>\n",
              "      <td>0050000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1177</th>\n",
              "      <td>Monica</td>\n",
              "      <td>I know!</td>\n",
              "      <td>sadness</td>\n",
              "      <td>0040010</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1178 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       speaker  ... annotation\n",
              "0       Phoebe  ...    0002120\n",
              "1       Monica  ...    1000130\n",
              "2         Ross  ...    3000200\n",
              "3     Chandler  ...    0500000\n",
              "4         Joey  ...    0040100\n",
              "...        ...  ...        ...\n",
              "1173    Monica  ...    2030000\n",
              "1174    Rachel  ...    0040010\n",
              "1175    Monica  ...    0050000\n",
              "1176    Rachel  ...    0050000\n",
              "1177    Monica  ...    0040010\n",
              "\n",
              "[1178 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "TkPP9iY2JnNo",
        "outputId": "ba39b790-1a3c-4cc5-9e7f-81e4490953bb"
      },
      "source": [
        "test_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>speaker</th>\n",
              "      <th>utterance</th>\n",
              "      <th>emotion</th>\n",
              "      <th>annotation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mark</td>\n",
              "      <td>Why do all youre coffee mugs have numbers on ...</td>\n",
              "      <td>surprise</td>\n",
              "      <td>2000030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Rachel</td>\n",
              "      <td>Oh. Thats so Monica can keep track. That way ...</td>\n",
              "      <td>non-neutral</td>\n",
              "      <td>2100011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Rachel</td>\n",
              "      <td>Y'know what?</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3000020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ross</td>\n",
              "      <td>It didnt.</td>\n",
              "      <td>neutral</td>\n",
              "      <td>5000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Frank</td>\n",
              "      <td>Okay, so what you used to have with Rachel, is...</td>\n",
              "      <td>joy</td>\n",
              "      <td>1300010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759</th>\n",
              "      <td>Phoebe</td>\n",
              "      <td>Hey, why dont you guys go get portraits done ...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>5000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2760</th>\n",
              "      <td>Monica</td>\n",
              "      <td>Thats a good idea! I bet they have one of tho...</td>\n",
              "      <td>joy</td>\n",
              "      <td>1400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2761</th>\n",
              "      <td>Phoebe</td>\n",
              "      <td>Yeah thats great! Next to that, Chandler won...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3100100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2762</th>\n",
              "      <td>Monica</td>\n",
              "      <td>Chandler what do you say?</td>\n",
              "      <td>neutral</td>\n",
              "      <td>5000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2763</th>\n",
              "      <td>Chandler</td>\n",
              "      <td>All right, but I should warn you, Im not goin...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4000100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2764 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       speaker  ... annotation\n",
              "0         Mark  ...    2000030\n",
              "1       Rachel  ...    2100011\n",
              "2       Rachel  ...    3000020\n",
              "3         Ross  ...    5000000\n",
              "4        Frank  ...    1300010\n",
              "...        ...  ...        ...\n",
              "2759    Phoebe  ...    5000000\n",
              "2760    Monica  ...    1400000\n",
              "2761    Phoebe  ...    3100100\n",
              "2762    Monica  ...    5000000\n",
              "2763  Chandler  ...    4000100\n",
              "\n",
              "[2764 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcuroaKIJ_HC"
      },
      "source": [
        "캐글 테스트 데이터"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2C-dya9A72XX"
      },
      "source": [
        "test = pd.read_csv('EN_Sentiment-Analysis/data_in/en_data.csv')#, encoding = 'unicode_escape')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "oY3824V37-1N",
        "outputId": "e65a7c0d-68ad-4ef1-8b26-9bdb2a03c7f2"
      },
      "source": [
        "test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>i_dialog</th>\n",
              "      <th>i_utterance</th>\n",
              "      <th>speaker</th>\n",
              "      <th>utterance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Phoebe</td>\n",
              "      <td>Alright, whadyou do with him?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Monica</td>\n",
              "      <td>Oh! You're awake!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>Joey</td>\n",
              "      <td>Then you gotta come clean with Ma! This is not...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Mr. Tribbiani</td>\n",
              "      <td>Yeah, but this is</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>Joey</td>\n",
              "      <td>I don't wanna hear it! Now go to my room!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1618</th>\n",
              "      <td>1618</td>\n",
              "      <td>150</td>\n",
              "      <td>14</td>\n",
              "      <td>Joey</td>\n",
              "      <td>Nooo.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1619</th>\n",
              "      <td>1619</td>\n",
              "      <td>150</td>\n",
              "      <td>15</td>\n",
              "      <td>Lauren</td>\n",
              "      <td>Hi, Kate!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1620</th>\n",
              "      <td>1620</td>\n",
              "      <td>150</td>\n",
              "      <td>16</td>\n",
              "      <td>Kate</td>\n",
              "      <td>Hi, Lauren.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1621</th>\n",
              "      <td>1621</td>\n",
              "      <td>150</td>\n",
              "      <td>17</td>\n",
              "      <td>Joey</td>\n",
              "      <td>Hi, Lauren.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1622</th>\n",
              "      <td>1622</td>\n",
              "      <td>150</td>\n",
              "      <td>18</td>\n",
              "      <td>Lauren</td>\n",
              "      <td>Hi, pig!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1623 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ...                                          utterance\n",
              "0        0  ...                      Alright, whadyou do with him?\n",
              "1        1  ...                                  Oh! You're awake!\n",
              "2        2  ...  Then you gotta come clean with Ma! This is not...\n",
              "3        3  ...                                  Yeah, but this is\n",
              "4        4  ...          I don't wanna hear it! Now go to my room!\n",
              "...    ...  ...                                                ...\n",
              "1618  1618  ...                                              Nooo.\n",
              "1619  1619  ...                                          Hi, Kate!\n",
              "1620  1620  ...                                        Hi, Lauren.\n",
              "1621  1621  ...                                        Hi, Lauren.\n",
              "1622  1622  ...                                           Hi, pig!\n",
              "\n",
              "[1623 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2yw2RWdLlrw"
      },
      "source": [
        "### 프랜즈 및 캐글테스트 마스크 처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6ewqAQpw_yN"
      },
      "source": [
        "프랜즈 데이터 마스크"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmliMLzI85i6",
        "outputId": "c97dbdbe-745d-4a40-b84f-fc42150aaf5c"
      },
      "source": [
        "print(train_data.shape)\n",
        "print(dev_data.shape)\n",
        "print(test_data.shape)\n",
        "print(test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10561, 4)\n",
            "(1178, 4)\n",
            "(2764, 4)\n",
            "(1623, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "jHIg8v28YXio",
        "outputId": "ccb9e5f4-a02a-4497-ab14-21af288618c8"
      },
      "source": [
        "print('리뷰의 최대 길이 :',max(len(l) for l in train_data['utterance']))\r\n",
        "print('리뷰의 평균 길이 :',sum(map(len, train_data['utterance']))/len(train_data['utterance']))\r\n",
        "plt.hist([len(s) for s in train_data['utterance']], bins=50)\r\n",
        "plt.xlabel('length of samples')\r\n",
        "plt.ylabel('number of samples')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "리뷰의 최대 길이 : 327\n",
            "리뷰의 평균 길이 : 39.68478363791308\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MaGztEyGbv6"
      },
      "source": [
        "def cleaning1(str):\n",
        "    replaceAll= str\n",
        "    only_english = re.sub('\\x92', '\\'', replaceAll)\n",
        "    return only_english"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmyUQewC7Hn0"
      },
      "source": [
        "def getInputsAndLabels(dataset):\n",
        "  data = dataset.copy(deep=True)\n",
        "  #data['utterance'] = data['utterance'].str.lower()\n",
        "\n",
        "  utterances = data['utterance']\n",
        "  utterances = [\"[CLS] \" + str(cleaning1(utterance)) + \" [SEP]\" for utterance in utterances]\n",
        "  \n",
        "  encoder = LabelEncoder()\n",
        "  labels = data['emotion'].values\n",
        "  encoder.fit(labels)\n",
        "  labels = encoder.transform(labels)\n",
        "\n",
        "  tokenizer = ElectraTokenizer.from_pretrained('google/electra-small-discriminator')\n",
        "  tokenized_texts = [tokenizer.tokenize(utterance) for utterance in utterances]\n",
        "\n",
        "  input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "  input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "  attention_masks = []\n",
        "  for seq in input_ids:\n",
        "      seq_mask = [float(i>0) for i in seq]\n",
        "      attention_masks.append(seq_mask)\n",
        "\n",
        "  return input_ids, labels, attention_masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EVlb_5RnptP"
      },
      "source": [
        "def getInputsFromTest(dataset):\n",
        "  data = dataset.copy(deep=True)\n",
        "\n",
        "  utterances = data['utterance']\n",
        "  utterances = [\"[CLS] \" + str(cleaning1(utterance)) + \" [SEP]\" for utterance in utterances]\n",
        "  \n",
        "  tokenizer = ElectraTokenizer.from_pretrained('google/electra-small-discriminator')\n",
        "  tokenized_texts = [tokenizer.tokenize(utterance) for utterance in utterances]\n",
        "\n",
        "  input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "  input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "  attention_masks = []\n",
        "  for seq in input_ids:\n",
        "      seq_mask = [float(i>0) for i in seq]\n",
        "      attention_masks.append(seq_mask)\n",
        "\n",
        "  return input_ids, attention_masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnirJQxrERms"
      },
      "source": [
        "def getIndex(dataset):\n",
        "  data = dataset.copy(deep = True)\n",
        "  input_index = data.id.tolist()\n",
        "  return torch.tensor(input_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwNgpRzc7lIv"
      },
      "source": [
        "train_inputs1, train_labels1, train_masks1 = getInputsAndLabels(train_data)\n",
        "dev_inputs, dev_labels, dev_masks = getInputsAndLabels(dev_data)\n",
        "test_inputs, test_labels, test_masks = getInputsAndLabels(test_data)\n",
        "test_inputs1, test_masks1 = getInputsFromTest(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REjFTEORMtXg",
        "outputId": "0671e50c-44aa-4245-b43f-f116315ff971"
      },
      "source": [
        "print('전체 프랜즈 학  습 데이터의 개수: {}'.format(len(train_inputs1)))\r\n",
        "print('전체 프랜즈 라  벨 데이터의 개수: {}'.format(len(train_labels1)))\r\n",
        "print('전체 프랜즈 마스크 데이터의 개수: {}'.format(len(train_masks1)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 프랜즈 학  습 데이터의 개수: 10561\n",
            "전체 프랜즈 라  벨 데이터의 개수: 10561\n",
            "전체 프랜즈 마스크 데이터의 개수: 10561\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLHfkY0Egk8u",
        "outputId": "387fe63d-a56c-4abb-d3e7-37ed8cf75538"
      },
      "source": [
        "print('전체 프랜즈 dev학  습 데이터의 개수: {}'.format(len(dev_inputs)))\r\n",
        "print('전체 프랜즈 dev라  벨 데이터의 개수: {}'.format(len(dev_labels)))\r\n",
        "print('전체 프랜즈 dev마스크 데이터의 개수: {}'.format(len(dev_masks)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 프랜즈 dev학  습 데이터의 개수: 1178\n",
            "전체 프랜즈 dev라  벨 데이터의 개수: 1178\n",
            "전체 프랜즈 dev마스크 데이터의 개수: 1178\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ju5oSOV85_AW",
        "outputId": "de9b4eba-538b-4e4a-cc60-6a92dd80b0a6"
      },
      "source": [
        "print('전체 프랜즈 test학  습 데이터의 개수: {}'.format(len(test_inputs)))\r\n",
        "print('전체 프랜즈 test라  벨 데이터의 개수: {}'.format(len(test_labels)))\r\n",
        "print('전체 프랜즈 test마스크 데이터의 개수: {}'.format(len(test_masks)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 프랜즈 test학  습 데이터의 개수: 2764\n",
            "전체 프랜즈 test라  벨 데이터의 개수: 2764\n",
            "전체 프랜즈 test마스크 데이터의 개수: 2764\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEVeWL7s5_Ck",
        "outputId": "6e0bf4c8-6edd-4afd-dc69-9cae2d7a5670"
      },
      "source": [
        "print('전체 프랜즈 test1 학  습 데이터의 개수: {}'.format(len(test_inputs1)))\r\n",
        "print('전체 프랜즈 test1 마스크 데이터의 개수: {}'.format(len(test_masks1)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 프랜즈 test1 학  습 데이터의 개수: 1623\n",
            "전체 프랜즈 test1 마스크 데이터의 개수: 1623\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gRXL7RnKWc1"
      },
      "source": [
        "## 1.2 IMDB 데이터"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "8x2NvIHnWyDz",
        "outputId": "e7f07bb1-bfd9-43bf-9533-56c49777d610"
      },
      "source": [
        "#IMDB data\n",
        "train_data2 = pd.read_csv('EN_Sentiment-Analysis/data_in/labeledTrainData.tsv', header = 0, delimiter = '\\t', quoting = 3)\n",
        "train_data2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"5814_8\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"With all this stuff going down at the moment ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"2381_9\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"7759_3\"</td>\n",
              "      <td>0</td>\n",
              "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"3630_4\"</td>\n",
              "      <td>0</td>\n",
              "      <td>\"It must be assumed that those who praised thi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"9495_8\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"Superbly trashy and wondrously unpretentious ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24995</th>\n",
              "      <td>\"3453_3\"</td>\n",
              "      <td>0</td>\n",
              "      <td>\"It seems like more consideration has gone int...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24996</th>\n",
              "      <td>\"5064_1\"</td>\n",
              "      <td>0</td>\n",
              "      <td>\"I don't believe they made this film. Complete...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24997</th>\n",
              "      <td>\"10905_3\"</td>\n",
              "      <td>0</td>\n",
              "      <td>\"Guy is a loser. Can't get girls, needs to bui...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24998</th>\n",
              "      <td>\"10194_3\"</td>\n",
              "      <td>0</td>\n",
              "      <td>\"This 30 minute documentary Buñuel made in the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24999</th>\n",
              "      <td>\"8478_8\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"I saw this movie as a child and it broke my h...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              id  sentiment                                             review\n",
              "0       \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
              "1       \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
              "2       \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...\n",
              "3       \"3630_4\"          0  \"It must be assumed that those who praised thi...\n",
              "4       \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ...\n",
              "...          ...        ...                                                ...\n",
              "24995   \"3453_3\"          0  \"It seems like more consideration has gone int...\n",
              "24996   \"5064_1\"          0  \"I don't believe they made this film. Complete...\n",
              "24997  \"10905_3\"          0  \"Guy is a loser. Can't get girls, needs to bui...\n",
              "24998  \"10194_3\"          0  \"This 30 minute documentary Buñuel made in the...\n",
              "24999   \"8478_8\"          1  \"I saw this movie as a child and it broke my h...\n",
              "\n",
              "[25000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qwU79HBKTG7"
      },
      "source": [
        "def cleaning_mv(str):\r\n",
        "    replaceAll= str\r\n",
        "    only_english = re.sub('<br />', '', replaceAll)\r\n",
        "    return only_english\r\n",
        "\r\n",
        "# 감정을 숫자로 변환\r\n",
        "def emotion_labeling_mv(emotion):\r\n",
        "   return{0 : 'angry',1:'joy'}[emotion]\r\n",
        "\r\n",
        "emotion_labels = []\r\n",
        "\r\n",
        "for e in train_data2['sentiment']:\r\n",
        "   emotion_labels.append(emotion_labeling_mv(e))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "MlahcjyeXlEd",
        "outputId": "fc19a32c-8be6-488c-8460-1c7fd4ed502c"
      },
      "source": [
        "train_data2['label'] = emotion_labels\n",
        "train_data2[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"5814_8\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"With all this stuff going down at the moment ...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"2381_9\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"7759_3\"</td>\n",
              "      <td>0</td>\n",
              "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
              "      <td>angry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"3630_4\"</td>\n",
              "      <td>0</td>\n",
              "      <td>\"It must be assumed that those who praised thi...</td>\n",
              "      <td>angry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"9495_8\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"Superbly trashy and wondrously unpretentious ...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>\"8196_8\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"I dont know why people think this is such a b...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>\"7166_2\"</td>\n",
              "      <td>0</td>\n",
              "      <td>\"This movie could have been very good, but com...</td>\n",
              "      <td>angry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>\"10633_1\"</td>\n",
              "      <td>0</td>\n",
              "      <td>\"I watched this video at a friend's house. I'm...</td>\n",
              "      <td>angry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>\"319_1\"</td>\n",
              "      <td>0</td>\n",
              "      <td>\"A friend of mine bought this film for £1, and...</td>\n",
              "      <td>angry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>\"8713_10\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"&lt;br /&gt;&lt;br /&gt;This movie is full of references....</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  ...  label\n",
              "0   \"5814_8\"  ...    joy\n",
              "1   \"2381_9\"  ...    joy\n",
              "2   \"7759_3\"  ...  angry\n",
              "3   \"3630_4\"  ...  angry\n",
              "4   \"9495_8\"  ...    joy\n",
              "5   \"8196_8\"  ...    joy\n",
              "6   \"7166_2\"  ...  angry\n",
              "7  \"10633_1\"  ...  angry\n",
              "8    \"319_1\"  ...  angry\n",
              "9  \"8713_10\"  ...    joy\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "T4XRvKqgYF9H",
        "outputId": "f9738888-f43f-4bad-ddb5-d55d94feaa8c"
      },
      "source": [
        "print('리뷰의 최대 길이 :',max(len(l) for l in train_data2['review']))\r\n",
        "print('리뷰의 평균 길이 :',sum(map(len, train_data2['review']))/len(train_data2['review']))\r\n",
        "plt.hist([len(s) for s in train_data2['review']], bins=50)\r\n",
        "plt.xlabel('length of samples')\r\n",
        "plt.ylabel('number of samples')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "리뷰의 최대 길이 : 13710\n",
            "리뷰의 평균 길이 : 1329.71056\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dt2vVwkoMLK7"
      },
      "source": [
        "### IMDB 데이터 마스크 처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxh0foPSY5c_"
      },
      "source": [
        "def getInputsAndLabels2(dataset):\n",
        "  data = dataset.copy(deep=True)\n",
        "\n",
        "  utterances = data['review']\n",
        "  utterances = [\"[CLS] \" + str(cleaning_mv(utterance)) + \" [SEP]\" for utterance in utterances]\n",
        "  \n",
        "  encoder = LabelEncoder()\n",
        "  labels = data['label'].values\n",
        "  encoder.fit(labels)\n",
        "  labels = encoder.transform(labels)\n",
        "\n",
        "  tokenizer = ElectraTokenizer.from_pretrained('google/electra-small-discriminator')\n",
        "  tokenized_texts = [tokenizer.tokenize(utterance) for utterance in utterances]\n",
        "\n",
        "  input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "  input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "  attention_masks = []\n",
        "  for seq in input_ids:\n",
        "      seq_mask = [float(i>0) for i in seq]\n",
        "      attention_masks.append(seq_mask)\n",
        "\n",
        "  return input_ids, labels, attention_masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYbyO19Mat-7"
      },
      "source": [
        "train_inputs2, train_labels2, train_masks2 = getInputsAndLabels2(train_data2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76qxmtnnLrOd",
        "outputId": "d9b7b090-add1-48c9-e8a3-8cd338af6622"
      },
      "source": [
        "print('전체 IMDB 학  습 데이터의 개수: {}'.format(len(train_inputs2)))\r\n",
        "print('전체 IMDB 라  벨 데이터의 개수: {}'.format(len(train_labels2)))\r\n",
        "print('전체 IMDB 마스크 데이터의 개수: {}'.format(len(train_masks2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 IMDB 학  습 데이터의 개수: 25000\n",
            "전체 IMDB 라  벨 데이터의 개수: 25000\n",
            "전체 IMDB 마스크 데이터의 개수: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHDouqzmMd8T"
      },
      "source": [
        "## 1.3 훈련 데이터 합치기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bZ_XvRUbaSh"
      },
      "source": [
        "train_inputs0 = []\n",
        "train_inputs0.extend(train_inputs1)\n",
        "train_inputs0.extend(train_inputs2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXAitKMdbxkx"
      },
      "source": [
        "train_labels0 = []\n",
        "train_labels0.extend(train_labels1)\n",
        "train_labels0.extend(train_labels2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzDiHKBMbxsg"
      },
      "source": [
        "train_masks0 = []\n",
        "train_masks0.extend(train_masks1)\n",
        "train_masks0.extend(train_masks2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUhqFV5sNgTc",
        "outputId": "b3cfdee6-dc7a-4681-ce65-5139b887dddd"
      },
      "source": [
        "print('전체 학  습 데이터의 개수: {}'.format(len(train_inputs0)))\r\n",
        "print('전체 라  벨 데이터의 개수: {}'.format(len(train_labels0)))\r\n",
        "print('전체 마스크 데이터의 개수: {}'.format(len(train_masks0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 학  습 데이터의 개수: 35561\n",
            "전체 라  벨 데이터의 개수: 35561\n",
            "전체 마스크 데이터의 개수: 35561\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0jKFX9b_RMo"
      },
      "source": [
        "train_inputs = torch.tensor(train_inputs0)\n",
        "train_labels = torch.tensor(train_labels0)\n",
        "train_masks = torch.tensor(train_masks0)\n",
        "\n",
        "dev_inputs = torch.tensor(dev_inputs)\n",
        "dev_labels = torch.tensor(dev_labels)\n",
        "dev_masks = torch.tensor(dev_masks)\n",
        "\n",
        "#test_index = getIndex(test)\n",
        "test_inputs = torch.tensor(test_inputs)\n",
        "test_labels = torch.tensor(test_labels)\n",
        "test_masks = torch.tensor(test_masks)\n",
        "\n",
        "test_index1 = getIndex(test)\n",
        "test_inputs1 = torch.tensor(test_inputs1)\n",
        "test_masks1 = torch.tensor(test_masks1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zl6EOni__5M"
      },
      "source": [
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "dev_data = TensorDataset(dev_inputs, dev_masks, dev_labels)\n",
        "dev_sampler = SequentialSampler(dev_data)\n",
        "dev_dataloader = DataLoader(dev_data, sampler=dev_sampler, batch_size=batch_size)\n",
        "\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "test_sampler = RandomSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n",
        "\n",
        "test_data1 = TensorDataset(test_index1, test_inputs1, test_masks1)\n",
        "test_sampler1 = RandomSampler(test_data1)\n",
        "test_dataloader1 = DataLoader(test_data1, sampler=test_sampler1, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AO2EtdExAmiG"
      },
      "source": [
        "# 2. 모델 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EN-mJst1Fn7x",
        "outputId": "3ccfba24-bf8e-4654-c966-a6d52a5c5a2d"
      },
      "source": [
        "# 디바이스 설정\n",
        "if torch.cuda.is_available():    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print('No GPU available, using the CPU instead.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla V100-SXM2-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xC8tp9PUAlAK",
        "outputId": "c5ceff00-43c7-4371-a001-daca6516f3a5"
      },
      "source": [
        "model = ElectraForSequenceClassification.from_pretrained('google/electra-small-generator', num_labels=8)\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at google/electra-small-generator were not used when initializing ElectraForSequenceClassification: ['generator_predictions.LayerNorm.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.dense.weight', 'generator_predictions.dense.bias', 'generator_lm_head.weight', 'generator_lm_head.bias']\n",
            "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-small-generator and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ElectraForSequenceClassification(\n",
              "  (electra): ElectraModel(\n",
              "    (embeddings): ElectraEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 128)\n",
              "      (token_type_embeddings): Embedding(2, 128)\n",
              "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (embeddings_project): Linear(in_features=128, out_features=256, bias=True)\n",
              "    (encoder): ElectraEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): ElectraClassificationHead(\n",
              "    (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=256, out_features=8, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXcncqM4Ghpl"
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, \n",
        "                  eps = 1e-8\n",
        "                )\n",
        "\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# 학습률을 조금씩 감소시키는 스케줄러 생성\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ol_8ST0tHTJX"
      },
      "source": [
        "# 3. 학습\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgM7XAN8HVPK"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# 정확도 계산 함수\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "def getF1Score(preds, labels):\n",
        "  pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "  labels_flat = labels.flatten()\n",
        "\n",
        "  return f1_score(labels_flat, pred_flat, average = None)\n",
        "\n",
        "# 시간 표시 함수\n",
        "def format_time(elapsed):\n",
        "    # 반올림\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # hh:mm:ss으로 형태 변경\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Xnc1vL3HcHF",
        "outputId": "2cfbcf2a-2468-4c83-f5fd-094f6ed37da6"
      },
      "source": [
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "model.zero_grad()\n",
        "\n",
        "# 에폭만큼 반복\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "    total_loss = 0\n",
        "    model.train()\n",
        "        \n",
        "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        if step % 500 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "             \n",
        "        outputs = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask, \n",
        "                        labels=b_labels)\n",
        "\n",
        "        loss = outputs[0]\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        model.zero_grad()\n",
        "\n",
        "    # 평균 로스 계산\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "    model.eval()\n",
        "    eval_loss, eval_accuracy, eval_f1 = 0, 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
        "    #for batch in validation_dataloader:\n",
        "    for batch in dev_dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        with torch.no_grad():     \n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        logits = outputs[0]\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "     \n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        # tmp_eval_f1 = getF1Score(logits, label_ids)\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "        # eval_f1 += tmp_eval_f1\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    # print(\"  F1: {0:.2f}\".format(eval_f1/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 20 ========\n",
            "Training...\n",
            "  Batch   500  of  1,112.    Elapsed: 0:00:45.\n",
            "  Batch 1,000  of  1,112.    Elapsed: 0:01:29.\n",
            "\n",
            "  Average training loss: 0.90\n",
            "  Training epcoh took: 0:01:39\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.49\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 20 ========\n",
            "Training...\n",
            "  Batch   500  of  1,112.    Elapsed: 0:00:44.\n",
            "  Batch 1,000  of  1,112.    Elapsed: 0:01:28.\n",
            "\n",
            "  Average training loss: 0.63\n",
            "  Training epcoh took: 0:01:38\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.53\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 20 ========\n",
            "Training...\n",
            "  Batch   500  of  1,112.    Elapsed: 0:00:45.\n",
            "  Batch 1,000  of  1,112.    Elapsed: 0:01:29.\n",
            "\n",
            "  Average training loss: 0.55\n",
            "  Training epcoh took: 0:01:39\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.56\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 20 ========\n",
            "Training...\n",
            "  Batch   500  of  1,112.    Elapsed: 0:00:44.\n",
            "  Batch 1,000  of  1,112.    Elapsed: 0:01:28.\n",
            "\n",
            "  Average training loss: 0.50\n",
            "  Training epcoh took: 0:01:38\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.56\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 5 / 20 ========\n",
            "Training...\n",
            "  Batch   500  of  1,112.    Elapsed: 0:00:44.\n",
            "  Batch 1,000  of  1,112.    Elapsed: 0:01:28.\n",
            "\n",
            "  Average training loss: 0.46\n",
            "  Training epcoh took: 0:01:38\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.54\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 6 / 20 ========\n",
            "Training...\n",
            "  Batch   500  of  1,112.    Elapsed: 0:00:44.\n",
            "  Batch 1,000  of  1,112.    Elapsed: 0:01:28.\n",
            "\n",
            "  Average training loss: 0.43\n",
            "  Training epcoh took: 0:01:38\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.57\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 7 / 20 ========\n",
            "Training...\n",
            "  Batch   500  of  1,112.    Elapsed: 0:00:44.\n",
            "  Batch 1,000  of  1,112.    Elapsed: 0:01:29.\n",
            "\n",
            "  Average training loss: 0.40\n",
            "  Training epcoh took: 0:01:39\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.56\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 8 / 20 ========\n",
            "Training...\n",
            "  Batch   500  of  1,112.    Elapsed: 0:00:44.\n",
            "  Batch 1,000  of  1,112.    Elapsed: 0:01:28.\n",
            "\n",
            "  Average training loss: 0.38\n",
            "  Training epcoh took: 0:01:38\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.56\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 9 / 20 ========\n",
            "Training...\n",
            "  Batch   500  of  1,112.    Elapsed: 0:00:44.\n",
            "  Batch 1,000  of  1,112.    Elapsed: 0:01:29.\n",
            "\n",
            "  Average training loss: 0.35\n",
            "  Training epcoh took: 0:01:39\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.55\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 10 / 20 ========\n",
            "Training...\n",
            "  Batch   500  of  1,112.    Elapsed: 0:00:44.\n",
            "  Batch 1,000  of  1,112.    Elapsed: 0:01:28.\n",
            "\n",
            "  Average training loss: 0.33\n",
            "  Training epcoh took: 0:01:38\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.56\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 11 / 20 ========\n",
            "Training...\n",
            "  Batch   500  of  1,112.    Elapsed: 0:00:44.\n",
            "  Batch 1,000  of  1,112.    Elapsed: 0:01:28.\n",
            "\n",
            "  Average training loss: 0.31\n",
            "  Training epcoh took: 0:01:38\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.57\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 12 / 20 ========\n",
            "Training...\n",
            "  Batch   500  of  1,112.    Elapsed: 0:00:45.\n",
            "  Batch 1,000  of  1,112.    Elapsed: 0:01:30.\n",
            "\n",
            "  Average training loss: 0.30\n",
            "  Training epcoh took: 0:01:40\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.57\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 13 / 20 ========\n",
            "Training...\n",
            "  Batch   500  of  1,112.    Elapsed: 0:00:45.\n",
            "  Batch 1,000  of  1,112.    Elapsed: 0:01:29.\n",
            "\n",
            "  Average training loss: 0.28\n",
            "  Training epcoh took: 0:01:39\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.57\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 14 / 20 ========\n",
            "Training...\n",
            "  Batch   500  of  1,112.    Elapsed: 0:00:44.\n",
            "  Batch 1,000  of  1,112.    Elapsed: 0:01:29.\n",
            "\n",
            "  Average training loss: 0.27\n",
            "  Training epcoh took: 0:01:39\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.55\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 15 / 20 ========\n",
            "Training...\n",
            "  Batch   500  of  1,112.    Elapsed: 0:00:44.\n",
            "  Batch 1,000  of  1,112.    Elapsed: 0:01:29.\n",
            "\n",
            "  Average training loss: 0.26\n",
            "  Training epcoh took: 0:01:39\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.57\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 16 / 20 ========\n",
            "Training...\n",
            "  Batch   500  of  1,112.    Elapsed: 0:00:45.\n",
            "  Batch 1,000  of  1,112.    Elapsed: 0:01:29.\n",
            "\n",
            "  Average training loss: 0.25\n",
            "  Training epcoh took: 0:01:39\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.56\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 17 / 20 ========\n",
            "Training...\n",
            "  Batch   500  of  1,112.    Elapsed: 0:00:44.\n",
            "  Batch 1,000  of  1,112.    Elapsed: 0:01:28.\n",
            "\n",
            "  Average training loss: 0.24\n",
            "  Training epcoh took: 0:01:39\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.55\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 18 / 20 ========\n",
            "Training...\n",
            "  Batch   500  of  1,112.    Elapsed: 0:00:44.\n",
            "  Batch 1,000  of  1,112.    Elapsed: 0:01:29.\n",
            "\n",
            "  Average training loss: 0.23\n",
            "  Training epcoh took: 0:01:39\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.56\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 19 / 20 ========\n",
            "Training...\n",
            "  Batch   500  of  1,112.    Elapsed: 0:00:44.\n",
            "  Batch 1,000  of  1,112.    Elapsed: 0:01:29.\n",
            "\n",
            "  Average training loss: 0.23\n",
            "  Training epcoh took: 0:01:39\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.56\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 20 / 20 ========\n",
            "Training...\n",
            "  Batch   500  of  1,112.    Elapsed: 0:00:44.\n",
            "  Batch 1,000  of  1,112.    Elapsed: 0:01:29.\n",
            "\n",
            "  Average training loss: 0.22\n",
            "  Training epcoh took: 0:01:38\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.56\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPFUE_ob5rk-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObIDCpRT5ru6"
      },
      "source": [
        "# 정확도 계산 함수\r\n",
        "def flat_accuracy(preds, labels):\r\n",
        "    \r\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\r\n",
        "    labels_flat = labels.flatten()\r\n",
        "\r\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\r\n",
        "\r\n",
        "# 시간 표시 함수\r\n",
        "def format_time(elapsed):\r\n",
        "\r\n",
        "    # 반올림\r\n",
        "    elapsed_rounded = int(round((elapsed)))\r\n",
        "    \r\n",
        "    # hh:mm:ss으로 형태 변경\r\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\r\n",
        "\r\n",
        "\r\n",
        "# f1-score parameter\r\n",
        "from sklearn.metrics import f1_score\r\n",
        "f1_score_avg = []\r\n",
        "trues = []\r\n",
        "preds = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96_z_Zfj5c9z",
        "outputId": "dd074947-ee88-4025-d71a-4bfe95c7333c"
      },
      "source": [
        "tmp_test_dataloader = DataLoader(test_data1, sampler=test_sampler1, batch_size=1)\r\n",
        "test_result = test.copy(deep = True)\r\n",
        "test_result = test_result.drop(columns = ['i_dialog', 'i_utterance', 'speaker'])\r\n",
        "test_result['Predicted'] = 'default'\r\n",
        "classes = [0,1,2,3,4,5,6,7]\r\n",
        "\r\n",
        "encoder = LabelEncoder()\r\n",
        "classes = train['emotion'].values\r\n",
        "encoder.fit(classes)\r\n",
        "classes = encoder.transform(classes)\r\n",
        "\r\n",
        "#시작 시간 설정\r\n",
        "t0 = time.time()\r\n",
        "\r\n",
        "# 평가모드로 변경\r\n",
        "model.eval()\r\n",
        "\r\n",
        "# 변수 초기화\r\n",
        "nb_eval_steps, nb_eval_examples = 0, 0\r\n",
        "\r\n",
        "# 데이터로더에서 배치만큼 반복하여 가져옴\r\n",
        "for step, batch in enumerate(tmp_test_dataloader):\r\n",
        "    # 경과 정보 표시\r\n",
        "    if step % 100 == 0 and not step == 0:\r\n",
        "        elapsed = format_time(time.time() - t0)\r\n",
        "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(tmp_test_dataloader), elapsed))\r\n",
        "\r\n",
        "    # 배치를 GPU에 넣음\r\n",
        "    batch = tuple(t.to(device) for t in batch)\r\n",
        "    \r\n",
        "    # 배치에서 데이터 추출\r\n",
        "    b_index, b_input_ids, b_input_mask = batch\r\n",
        "    \r\n",
        "    # 그래디언트 계산 안함\r\n",
        "    with torch.no_grad():     \r\n",
        "        # Forward 수행\r\n",
        "        outputs = model(b_input_ids, \r\n",
        "                        token_type_ids=None, \r\n",
        "                        attention_mask=b_input_mask)\r\n",
        "    \r\n",
        "    # 로스 구함\r\n",
        "    logits = outputs[0]\r\n",
        "\r\n",
        "    # CPU로 데이터 이동\r\n",
        "    logits = logits.detach().cpu().numpy()\r\n",
        "    idx = b_index.item()\r\n",
        "    test_result['Predicted'][idx] = encoder.classes_[np.argmax(logits)]\r\n",
        "    \r\n",
        "\r\n",
        "    nb_eval_steps += 1\r\n",
        "\r\n",
        "print(\"\")\r\n",
        "print(\"Test took: {:}\".format(format_time(time.time() - t0)))\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:47: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch   100  of  1,623.    Elapsed: 0:00:02.\n",
            "  Batch   200  of  1,623.    Elapsed: 0:00:03.\n",
            "  Batch   300  of  1,623.    Elapsed: 0:00:04.\n",
            "  Batch   400  of  1,623.    Elapsed: 0:00:06.\n",
            "  Batch   500  of  1,623.    Elapsed: 0:00:07.\n",
            "  Batch   600  of  1,623.    Elapsed: 0:00:08.\n",
            "  Batch   700  of  1,623.    Elapsed: 0:00:10.\n",
            "  Batch   800  of  1,623.    Elapsed: 0:00:11.\n",
            "  Batch   900  of  1,623.    Elapsed: 0:00:13.\n",
            "  Batch 1,000  of  1,623.    Elapsed: 0:00:14.\n",
            "  Batch 1,100  of  1,623.    Elapsed: 0:00:15.\n",
            "  Batch 1,200  of  1,623.    Elapsed: 0:00:17.\n",
            "  Batch 1,300  of  1,623.    Elapsed: 0:00:18.\n",
            "  Batch 1,400  of  1,623.    Elapsed: 0:00:19.\n",
            "  Batch 1,500  of  1,623.    Elapsed: 0:00:21.\n",
            "  Batch 1,600  of  1,623.    Elapsed: 0:00:22.\n",
            "\n",
            "Test took: 0:00:22\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ipkm5slB9o4U",
        "outputId": "a653db3b-f460-4bd8-ee77-d1a69af04d85"
      },
      "source": [
        "test_result['Predicted']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0           neutral\n",
              "1          surprise\n",
              "2       non-neutral\n",
              "3           neutral\n",
              "4       non-neutral\n",
              "           ...     \n",
              "1618    non-neutral\n",
              "1619            joy\n",
              "1620        neutral\n",
              "1621        neutral\n",
              "1622    non-neutral\n",
              "Name: Predicted, Length: 1623, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "4J6KOF21GXRA",
        "outputId": "eef1b150-7c51-4fb1-d29f-7e4c3ba620b9"
      },
      "source": [
        "test_result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>utterance</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Alright, whadyou do with him?</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Oh! You're awake!</td>\n",
              "      <td>surprise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Then you gotta come clean with Ma! This is not...</td>\n",
              "      <td>non-neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Yeah, but this is</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>I don't wanna hear it! Now go to my room!</td>\n",
              "      <td>non-neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1618</th>\n",
              "      <td>1618</td>\n",
              "      <td>Nooo.</td>\n",
              "      <td>non-neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1619</th>\n",
              "      <td>1619</td>\n",
              "      <td>Hi, Kate!</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1620</th>\n",
              "      <td>1620</td>\n",
              "      <td>Hi, Lauren.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1621</th>\n",
              "      <td>1621</td>\n",
              "      <td>Hi, Lauren.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1622</th>\n",
              "      <td>1622</td>\n",
              "      <td>Hi, pig!</td>\n",
              "      <td>non-neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1623 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        id                                          utterance    Predicted\n",
              "0        0                      Alright, whadyou do with him?      neutral\n",
              "1        1                                  Oh! You're awake!     surprise\n",
              "2        2  Then you gotta come clean with Ma! This is not...  non-neutral\n",
              "3        3                                  Yeah, but this is      neutral\n",
              "4        4          I don't wanna hear it! Now go to my room!  non-neutral\n",
              "...    ...                                                ...          ...\n",
              "1618  1618                                              Nooo.  non-neutral\n",
              "1619  1619                                          Hi, Kate!          joy\n",
              "1620  1620                                        Hi, Lauren.      neutral\n",
              "1621  1621                                        Hi, Lauren.      neutral\n",
              "1622  1622                                           Hi, pig!  non-neutral\n",
              "\n",
              "[1623 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9a63MukyIayn"
      },
      "source": [
        "test_result.drop(labels='utterance', axis=\"columns\", inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "bHF0VDTYIa1K",
        "outputId": "4960218e-0b42-4d71-df34-cfd2efac509b"
      },
      "source": [
        "DATA_OUT_NAME = \"submission_friends_electra_M\"+ str(MAX_LEN) + \"_B\"+ str(batch_size) + \"_E\"+ str(epochs) + \".csv\"\r\n",
        "\r\n",
        "test_csv = test_result.to_csv(DATA_OUT_NAME, columns=['id', 'Predicted'], index=False)\r\n",
        "from google.colab import files\r\n",
        "\r\n",
        "files.download(DATA_OUT_NAME)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_50d67196-c945-442e-9a9a-84d4e8dfe92a\", \"submission_friends_electra_M128_B32_E20.csv\", 20733)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4SMSF3hGXVw"
      },
      "source": [
        "# 정확도 계산 함수\r\n",
        "def flat_accuracy(preds, labels):\r\n",
        "    \r\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\r\n",
        "    labels_flat = labels.flatten()\r\n",
        "\r\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\r\n",
        "\r\n",
        "# 시간 표시 함수\r\n",
        "def format_time(elapsed):\r\n",
        "\r\n",
        "    # 반올림\r\n",
        "    elapsed_rounded = int(round((elapsed)))\r\n",
        "    \r\n",
        "    # hh:mm:ss으로 형태 변경\r\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\r\n",
        "\r\n",
        "\r\n",
        "# f1-score parameter\r\n",
        "from sklearn.metrics import f1_score\r\n",
        "f1_score_avg = []\r\n",
        "trues = []\r\n",
        "preds = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyd_9TE3PSXR",
        "outputId": "b7edbf0a-c2b8-4d57-9b6d-0fc8f06c2223"
      },
      "source": [
        "#시작 시간 설정\n",
        "t0 = time.time()\n",
        "#test_result = test.copy(deep = True)\n",
        "#test_result = test_result.drop(columns = ['i_dialog', 'i_utterance', 'speaker'])\n",
        "#test_result['Predicted'] = 'default'\n",
        "\n",
        "# 평가모드로 변경\n",
        "model.eval()\n",
        "\n",
        "# 변수 초기화\n",
        "eval_loss, eval_accuracy = 0, 0\n",
        "nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "# 데이터로더에서 배치만큼 반복하여 가져옴\n",
        "for step, batch in enumerate(test_dataloader):\n",
        "    # 경과 정보 표시\n",
        "    if step % 100 == 0 and not step == 0:\n",
        "        elapsed = format_time(time.time() - t0)\n",
        "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n",
        "\n",
        "    # 배치를 GPU에 넣음\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    \n",
        "    # 배치에서 데이터 추출\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    #b_index, b_input_ids, b_input_mask = batch\n",
        "    #b_input_ids, b_input_mask, b_labels = batch\n",
        "    \n",
        "    # 그래디언트 계산 안함\n",
        "    with torch.no_grad():     \n",
        "        # Forward 수행\n",
        "        outputs = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask)\n",
        "    \n",
        "    # 로스 구함\n",
        "    logits = outputs[0]\n",
        "\n",
        "    # CPU로 데이터 이동\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "   #\n",
        "    pred_flat = np.argmax(logits, axis=1).flatten()\n",
        "    trues_flat = label_ids.flatten()\n",
        "    trues.extend(trues_flat)\n",
        "    preds.extend(pred_flat)\n",
        "    \n",
        "    # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
        "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "    nb_eval_steps += 1\n",
        "\n",
        "print(\"\")\n",
        "print(\"Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "print(\"  f1 score macro: {0: 2f}\".format(f1_score(y_true=trues,y_pred= preds, labels = [0,1,2,3,4,5,6,7], average='macro')))\n",
        "print(\"  f1 score micro: {0: 2f}\".format(f1_score(y_true=trues, y_pred= preds, labels = [0,1,2,3,4,5,6,7],average='micro')))\n",
        "print(\"  f1 score weighted: {0: 2f}\".format(f1_score(y_true=trues, y_pred= preds, labels = [0,1,2,3,4,5,6,7],average='weighted')))\n",
        "print(\"  f1 score none: {f1_score(y_true=trues, y_pred= preds, labels = [0,1,2,3,4,5,6,7],average=None)}\")\n",
        "print(\"Test took: {:}\".format(format_time(time.time() - t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Accuracy: 0.58\n",
            "  f1 score macro:  0.385057\n",
            "  f1 score micro:  0.581404\n",
            "  f1 score weighted:  0.572567\n",
            "  f1 score none: {f1_score(y_true=trues, y_pred= preds, labels = [0,1,2,3,4,5,6,7],average=None)}\n",
            "Test took: 0:00:01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDrBOhu1K-Eh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}