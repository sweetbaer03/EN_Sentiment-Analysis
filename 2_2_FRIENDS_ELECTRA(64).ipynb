{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2-2. FRIENDS_ELECTRA(64).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1UhC_svCNScndorgU2jl1jtVlfpFVcm3B",
      "authorship_tag": "ABX9TyPtenzeML836hp/pF3K4yGm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9a42a070818146aba1134e39e6b239d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cad55e652be349ee992b8544e0ec7587",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bd601803c81045c486845de25189ed0f",
              "IPY_MODEL_a51745e71fdf40a1a3370c56208a6c26"
            ]
          }
        },
        "cad55e652be349ee992b8544e0ec7587": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bd601803c81045c486845de25189ed0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2ae89473effc464b917834e166dd1116",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8c3daeb4650f4d52bda52a9b9b485876"
          }
        },
        "a51745e71fdf40a1a3370c56208a6c26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a685dd26e6c84fffa900e4cd6c9e8cf2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:03&lt;00:00, 74.0kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5d8c9ea6f5f34b7d9c7bc1422ea87990"
          }
        },
        "2ae89473effc464b917834e166dd1116": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8c3daeb4650f4d52bda52a9b9b485876": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a685dd26e6c84fffa900e4cd6c9e8cf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5d8c9ea6f5f34b7d9c7bc1422ea87990": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sweetbaer03/EN_Sentiment-Analysis/blob/main/2_2_FRIENDS_ELECTRA(64).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tb0PNX9aZi0p"
      },
      "source": [
        "**FRIENDS Sentiment Analysis**\r\n",
        "\r\n",
        "\r\n",
        "ELECTRA 모델 사용 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKkEByjh5y_h",
        "outputId": "f26b740b-ad92-4de6-bb08-1d4eae53c8b9"
      },
      "source": [
        "#transformers 설치(colab 사용시)\r\n",
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/0c/7d5950fcd80b029be0a8891727ba21e0cd27692c407c51261c3c921f6da3/transformers-4.1.1-py3-none-any.whl (1.5MB)\n",
            "\r\u001b[K     |▏                               | 10kB 19.7MB/s eta 0:00:01\r\u001b[K     |▍                               | 20kB 23.3MB/s eta 0:00:01\r\u001b[K     |▋                               | 30kB 25.6MB/s eta 0:00:01\r\u001b[K     |▉                               | 40kB 20.4MB/s eta 0:00:01\r\u001b[K     |█                               | 51kB 16.7MB/s eta 0:00:01\r\u001b[K     |█▎                              | 61kB 18.3MB/s eta 0:00:01\r\u001b[K     |█▌                              | 71kB 12.7MB/s eta 0:00:01\r\u001b[K     |█▊                              | 81kB 13.7MB/s eta 0:00:01\r\u001b[K     |██                              | 92kB 13.8MB/s eta 0:00:01\r\u001b[K     |██▏                             | 102kB 13.0MB/s eta 0:00:01\r\u001b[K     |██▍                             | 112kB 13.0MB/s eta 0:00:01\r\u001b[K     |██▋                             | 122kB 13.0MB/s eta 0:00:01\r\u001b[K     |██▉                             | 133kB 13.0MB/s eta 0:00:01\r\u001b[K     |███                             | 143kB 13.0MB/s eta 0:00:01\r\u001b[K     |███▎                            | 153kB 13.0MB/s eta 0:00:01\r\u001b[K     |███▌                            | 163kB 13.0MB/s eta 0:00:01\r\u001b[K     |███▊                            | 174kB 13.0MB/s eta 0:00:01\r\u001b[K     |████                            | 184kB 13.0MB/s eta 0:00:01\r\u001b[K     |████▏                           | 194kB 13.0MB/s eta 0:00:01\r\u001b[K     |████▎                           | 204kB 13.0MB/s eta 0:00:01\r\u001b[K     |████▌                           | 215kB 13.0MB/s eta 0:00:01\r\u001b[K     |████▊                           | 225kB 13.0MB/s eta 0:00:01\r\u001b[K     |█████                           | 235kB 13.0MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 245kB 13.0MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 256kB 13.0MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 266kB 13.0MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 276kB 13.0MB/s eta 0:00:01\r\u001b[K     |██████                          | 286kB 13.0MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 296kB 13.0MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 307kB 13.0MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 317kB 13.0MB/s eta 0:00:01\r\u001b[K     |███████                         | 327kB 13.0MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 337kB 13.0MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 348kB 13.0MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 358kB 13.0MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 368kB 13.0MB/s eta 0:00:01\r\u001b[K     |████████                        | 378kB 13.0MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 389kB 13.0MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 399kB 13.0MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 409kB 13.0MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 419kB 13.0MB/s eta 0:00:01\r\u001b[K     |█████████                       | 430kB 13.0MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 440kB 13.0MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 450kB 13.0MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 460kB 13.0MB/s eta 0:00:01\r\u001b[K     |██████████                      | 471kB 13.0MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 481kB 13.0MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 491kB 13.0MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 501kB 13.0MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 512kB 13.0MB/s eta 0:00:01\r\u001b[K     |███████████                     | 522kB 13.0MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 532kB 13.0MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 542kB 13.0MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 552kB 13.0MB/s eta 0:00:01\r\u001b[K     |████████████                    | 563kB 13.0MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 573kB 13.0MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 583kB 13.0MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 593kB 13.0MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 604kB 13.0MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 614kB 13.0MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 624kB 13.0MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 634kB 13.0MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 645kB 13.0MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 655kB 13.0MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 665kB 13.0MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 675kB 13.0MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 686kB 13.0MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 696kB 13.0MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 706kB 13.0MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 716kB 13.0MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 727kB 13.0MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 737kB 13.0MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 747kB 13.0MB/s eta 0:00:01\r\u001b[K     |████████████████                | 757kB 13.0MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 768kB 13.0MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 778kB 13.0MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 788kB 13.0MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 798kB 13.0MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 808kB 13.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 819kB 13.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 829kB 13.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 839kB 13.0MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 849kB 13.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 860kB 13.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 870kB 13.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 880kB 13.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 890kB 13.0MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 901kB 13.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 911kB 13.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 921kB 13.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 931kB 13.0MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 942kB 13.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 952kB 13.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 962kB 13.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 972kB 13.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 983kB 13.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 993kB 13.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.0MB 13.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.0MB 13.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.0MB 13.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.0MB 13.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.0MB 13.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.1MB 13.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.1MB 13.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.1MB 13.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.1MB 13.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.1MB 13.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.1MB 13.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.1MB 13.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.1MB 13.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.1MB 13.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.1MB 13.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.2MB 13.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.2MB 13.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.2MB 13.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.2MB 13.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.2MB 13.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.2MB 13.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.2MB 13.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.2MB 13.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.2MB 13.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.2MB 13.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.3MB 13.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.3MB 13.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.3MB 13.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.3MB 13.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.3MB 13.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.3MB 13.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.3MB 13.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.3MB 13.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.3MB 13.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.4MB 13.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.4MB 13.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.4MB 13.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.4MB 13.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.4MB 13.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.4MB 13.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.4MB 13.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.4MB 13.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.4MB 13.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.4MB 13.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.5MB 13.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.5MB 13.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.5MB 13.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.5MB 13.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.5MB 13.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.5MB 13.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.5MB 13.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 38.6MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 44.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=9b5243157fdf60c9fffc7cf3eb7f3d103e403b704774874a2600e2e7a4edd6c5\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4L8v9ECIs-k"
      },
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import datetime\n",
        "import json\n",
        "import re\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from transformers import ElectraTokenizer, ElectraForSequenceClassification\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIZWo5sLZptB"
      },
      "source": [
        "# 데이터처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7b2jnOOJeaSe",
        "outputId": "656092fd-1d46-4a1a-a7d6-5d9de7ac7224"
      },
      "source": [
        "!git clone https://github.com/sweetbaer03/EN_Sentiment-Analysis.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'EN_Sentiment-Analysis'...\n",
            "remote: Enumerating objects: 44, done.\u001b[K\n",
            "remote: Counting objects: 100% (44/44), done.\u001b[K\n",
            "remote: Compressing objects: 100% (41/41), done.\u001b[K\n",
            "remote: Total 44 (delta 18), reused 6 (delta 1), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (44/44), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLlzf3XhZsG3"
      },
      "source": [
        "#파라미터 수정\r\n",
        "MAX_LEN = 85\r\n",
        "batch_size = 64\r\n",
        "epochs = 20\r\n",
        "\r\n",
        "TOKEN_MODEL = 'google/electra-small-discriminator'\r\n",
        "TRAIN_MODEL = 'google/electra-small-generator'\r\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jxeGmpdZviu"
      },
      "source": [
        "## 1.1 프렌즈 / 캐글 테스트 데이터"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dve0WGvuKyaZ"
      },
      "source": [
        "def jsonToDf(file_name):\n",
        "  with open(file_name, encoding = 'utf-8', mode = 'r') as file:\n",
        "    json_array = json.load(file)\n",
        "  \n",
        "  result = pd.DataFrame.from_dict(json_array[0])\n",
        "\n",
        "  is_first = True\n",
        "  for array in json_array:\n",
        "    if is_first:\n",
        "      is_first = False\n",
        "      continue\n",
        "    \n",
        "    temp_df = pd.DataFrame.from_dict(array)\n",
        "    result = result.append(temp_df, ignore_index = True)\n",
        "\n",
        "  return result"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBb5PrmqesC-"
      },
      "source": [
        "train_data = jsonToDf('EN_Sentiment-Analysis/data_in/friends_train.json')\r\n",
        "dev_data   = jsonToDf('EN_Sentiment-Analysis/data_in/friends_dev.json')\r\n",
        "test_data  = jsonToDf('EN_Sentiment-Analysis/data_in/friends_test.json')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGBQ3XLFUMXI"
      },
      "source": [
        "#합치기 위해 포멧 통일\r\n",
        "train_data.drop(labels=['speaker','annotation'], axis=\"columns\", inplace=True)\r\n",
        "dev_data.drop(labels=['speaker','annotation'], axis=\"columns\", inplace=True)\r\n",
        "test_data.drop(labels=['speaker','annotation'], axis=\"columns\", inplace=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtQIjp9yesD7"
      },
      "source": [
        "emotions = train_data['emotion'].values"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4L8yxjEZ6TN"
      },
      "source": [
        "**캐글** 테스트 데이터"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdnQa_w-Z-Ep"
      },
      "source": [
        "test_df = pd.read_csv('EN_Sentiment-Analysis/data_in/en_data.csv')#, encoding = 'unicode_escape')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "YFJzryJVZ-HR",
        "outputId": "b4b22a12-ff54-44bb-cb0d-3c9e24ccde84"
      },
      "source": [
        "test_df"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>i_dialog</th>\n",
              "      <th>i_utterance</th>\n",
              "      <th>speaker</th>\n",
              "      <th>utterance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Phoebe</td>\n",
              "      <td>Alright, whadyou do with him?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Monica</td>\n",
              "      <td>Oh! You're awake!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>Joey</td>\n",
              "      <td>Then you gotta come clean with Ma! This is not...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Mr. Tribbiani</td>\n",
              "      <td>Yeah, but this is</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>Joey</td>\n",
              "      <td>I don't wanna hear it! Now go to my room!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1618</th>\n",
              "      <td>1618</td>\n",
              "      <td>150</td>\n",
              "      <td>14</td>\n",
              "      <td>Joey</td>\n",
              "      <td>Nooo.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1619</th>\n",
              "      <td>1619</td>\n",
              "      <td>150</td>\n",
              "      <td>15</td>\n",
              "      <td>Lauren</td>\n",
              "      <td>Hi, Kate!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1620</th>\n",
              "      <td>1620</td>\n",
              "      <td>150</td>\n",
              "      <td>16</td>\n",
              "      <td>Kate</td>\n",
              "      <td>Hi, Lauren.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1621</th>\n",
              "      <td>1621</td>\n",
              "      <td>150</td>\n",
              "      <td>17</td>\n",
              "      <td>Joey</td>\n",
              "      <td>Hi, Lauren.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1622</th>\n",
              "      <td>1622</td>\n",
              "      <td>150</td>\n",
              "      <td>18</td>\n",
              "      <td>Lauren</td>\n",
              "      <td>Hi, pig!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1623 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ...                                          utterance\n",
              "0        0  ...                      Alright, whadyou do with him?\n",
              "1        1  ...                                  Oh! You're awake!\n",
              "2        2  ...  Then you gotta come clean with Ma! This is not...\n",
              "3        3  ...                                  Yeah, but this is\n",
              "4        4  ...          I don't wanna hear it! Now go to my room!\n",
              "...    ...  ...                                                ...\n",
              "1618  1618  ...                                              Nooo.\n",
              "1619  1619  ...                                          Hi, Kate!\n",
              "1620  1620  ...                                        Hi, Lauren.\n",
              "1621  1621  ...                                        Hi, Lauren.\n",
              "1622  1622  ...                                           Hi, pig!\n",
              "\n",
              "[1623 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3_Pd54TaBP5"
      },
      "source": [
        "### 프랜즈 및 캐글테스트 마스크 처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYWmejP_aDaj"
      },
      "source": [
        "프랜즈 데이터 마스크"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZM1ZPu__Z-Je",
        "outputId": "a5792d4a-91e3-4f2d-e76f-7344a7d873f8"
      },
      "source": [
        "print(train_data.shape)\r\n",
        "print(dev_data.shape)\r\n",
        "print(test_data.shape)\r\n",
        "print(test_df.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10561, 2)\n",
            "(1178, 2)\n",
            "(2764, 2)\n",
            "(1623, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYefryyFaFsl"
      },
      "source": [
        "def cleaning1(str):\r\n",
        "    replaceAll= str\r\n",
        "    only_english = re.sub('\\x92', '\\'', replaceAll)\r\n",
        "    return only_english\r\n",
        "\r\n",
        "\r\n",
        "def getInputsAndLabels(dataset):\r\n",
        "  data = dataset.copy(deep=True)\r\n",
        "\r\n",
        "  utterances = data['utterance']\r\n",
        "  utterances = [\"[CLS] \" + str(cleaning1(utterance)) + \" [SEP]\" for utterance in utterances]#이거다!\r\n",
        "  \r\n",
        "  encoder = LabelEncoder()\r\n",
        "  labels = data['emotion'].values\r\n",
        "  encoder.fit(labels)\r\n",
        "  labels = encoder.transform(labels)\r\n",
        "\r\n",
        "  tokenizer = ElectraTokenizer.from_pretrained(TOKEN_MODEL, do_lower_case=False)\r\n",
        "  tokenized_texts = [tokenizer.tokenize(utterance) for utterance in utterances]\r\n",
        "\r\n",
        "  input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\r\n",
        "  input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\r\n",
        "\r\n",
        "  attention_masks = []\r\n",
        "  for seq in input_ids:\r\n",
        "      seq_mask = [float(i>0) for i in seq]\r\n",
        "      attention_masks.append(seq_mask)\r\n",
        "\r\n",
        "  return input_ids, labels, attention_masks\r\n",
        "\r\n",
        "\r\n",
        "def getInputsFromTest(dataset):\r\n",
        "  data = dataset.copy(deep=True)\r\n",
        "\r\n",
        "  utterances = data['utterance']\r\n",
        "  utterances = [\"[CLS] \" + str(cleaning1(utterance)) + \" [SEP]\" for utterance in utterances]#이거다!\r\n",
        "  \r\n",
        "  tokenizer = ElectraTokenizer.from_pretrained(TOKEN_MODEL, do_lower_case=False)\r\n",
        "  tokenized_texts = [tokenizer.tokenize(utterance) for utterance in utterances]\r\n",
        "\r\n",
        "  input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\r\n",
        "  input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\r\n",
        "\r\n",
        "  attention_masks = []\r\n",
        "  for seq in input_ids:\r\n",
        "      seq_mask = [float(i>0) for i in seq]\r\n",
        "      attention_masks.append(seq_mask)\r\n",
        "\r\n",
        "  return input_ids, attention_masks\r\n",
        "\r\n",
        "\r\n",
        "def getIndex(dataset):\r\n",
        "  data = dataset.copy(deep = True)\r\n",
        "  input_index = data.id.tolist()\r\n",
        "  return torch.tensor(input_index)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "9a42a070818146aba1134e39e6b239d1",
            "cad55e652be349ee992b8544e0ec7587",
            "bd601803c81045c486845de25189ed0f",
            "a51745e71fdf40a1a3370c56208a6c26",
            "2ae89473effc464b917834e166dd1116",
            "8c3daeb4650f4d52bda52a9b9b485876",
            "a685dd26e6c84fffa900e4cd6c9e8cf2",
            "5d8c9ea6f5f34b7d9c7bc1422ea87990"
          ]
        },
        "id": "FnYXHQddaFKq",
        "outputId": "0cf1fee7-fe39-4207-89fd-5f75e8eaa9ce"
      },
      "source": [
        "train_inputs1, train_labels1, train_masks1 = getInputsAndLabels(train_data)\r\n",
        "dev_inputs, dev_labels, dev_masks = getInputsAndLabels(dev_data)\r\n",
        "test_inputs, test_labels, test_masks = getInputsAndLabels(test_data)\r\n",
        "test_df_inputs, test_df_masks = getInputsFromTest(test_df)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9a42a070818146aba1134e39e6b239d1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bccL-4SyaYPk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09823f37-a2c5-4d9d-bc1d-036de068e039"
      },
      "source": [
        "print('전체 프랜즈 학  습 데이터의 개수: {}'.format(len(train_inputs1)))\r\n",
        "print('전체 프랜즈 라  벨 데이터의 개수: {}'.format(len(train_labels1)))\r\n",
        "print('전체 프랜즈 마스크 데이터의 개수: {}'.format(len(train_masks1)))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 프랜즈 학  습 데이터의 개수: 10561\n",
            "전체 프랜즈 라  벨 데이터의 개수: 10561\n",
            "전체 프랜즈 마스크 데이터의 개수: 10561\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKJmHndEaYSM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d45aaba-f990-43ac-c7a5-0c26535980b6"
      },
      "source": [
        "print('전체 프랜즈 dev학  습 데이터의 개수: {}'.format(len(dev_inputs)))\r\n",
        "print('전체 프랜즈 dev라  벨 데이터의 개수: {}'.format(len(dev_labels)))\r\n",
        "print('전체 프랜즈 dev마스크 데이터의 개수: {}'.format(len(dev_masks)))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 프랜즈 dev학  습 데이터의 개수: 1178\n",
            "전체 프랜즈 dev라  벨 데이터의 개수: 1178\n",
            "전체 프랜즈 dev마스크 데이터의 개수: 1178\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCA3Y21JaYVG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9aadf3ff-2c78-4f12-bd3a-c46fd44e2fe3"
      },
      "source": [
        "print('전체 프랜즈 test학  습 데이터의 개수: {}'.format(len(test_inputs)))\r\n",
        "print('전체 프랜즈 test라  벨 데이터의 개수: {}'.format(len(test_labels)))\r\n",
        "print('전체 프랜즈 test마스크 데이터의 개수: {}'.format(len(test_masks)))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 프랜즈 test학  습 데이터의 개수: 2764\n",
            "전체 프랜즈 test라  벨 데이터의 개수: 2764\n",
            "전체 프랜즈 test마스크 데이터의 개수: 2764\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHvhA-fDaYXf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db719db0-06bc-4bb1-e42a-2faa1c78f54b"
      },
      "source": [
        "print('전체 프랜즈 test1 학  습 데이터의 개수: {}'.format(len(test_df_inputs)))\r\n",
        "print('전체 프랜즈 test1 마스크 데이터의 개수: {}'.format(len(test_df_masks)))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 프랜즈 test1 학  습 데이터의 개수: 1623\n",
            "전체 프랜즈 test1 마스크 데이터의 개수: 1623\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ybz5PtDcW8P"
      },
      "source": [
        "train_masks0 = []\r\n",
        "train_masks0.extend(train_masks1)\r\n",
        "#train_masks0.extend(train_masks2)\r\n",
        "#train_masks0.extend(train_masks3)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiRnsncnU6HV"
      },
      "source": [
        "train_labels0 = []\r\n",
        "train_labels0.extend(train_labels1)\r\n",
        "#train_labels0.extend(train_labels2)\r\n",
        "#train_labels0.extend(train_labels3)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xb7JaB6bU6Kz"
      },
      "source": [
        "train_inputs0 = []\r\n",
        "train_inputs0.extend(train_inputs1)\r\n",
        "#train_inputs0.extend(train_inputs2)\r\n",
        "#train_inputs0.extend(train_inputs3)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m15u04rcW6A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e158632c-8513-4081-c8c4-481c1a053573"
      },
      "source": [
        "print('전체 학  습 데이터의 개수: {}'.format(len(train_inputs0)))\r\n",
        "print('전체 라  벨 데이터의 개수: {}'.format(len(train_labels0)))\r\n",
        "print('전체 마스크 데이터의 개수: {}'.format(len(train_masks0)))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 학  습 데이터의 개수: 10561\n",
            "전체 라  벨 데이터의 개수: 10561\n",
            "전체 마스크 데이터의 개수: 10561\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_xnZrX_cW1s"
      },
      "source": [
        "train_inputs = torch.tensor(train_inputs0)\r\n",
        "train_labels = torch.tensor(train_labels0)\r\n",
        "train_masks = torch.tensor(train_masks0)\r\n",
        "\r\n",
        "dev_inputs = torch.tensor(dev_inputs)\r\n",
        "dev_labels = torch.tensor(dev_labels)\r\n",
        "dev_masks = torch.tensor(dev_masks)\r\n",
        "\r\n",
        "test_inputs = torch.tensor(test_inputs)\r\n",
        "test_labels = torch.tensor(test_labels)\r\n",
        "test_masks = torch.tensor(test_masks)\r\n",
        "\r\n",
        "test_df_index = getIndex(test_df)\r\n",
        "test_df_inputs = torch.tensor(test_df_inputs)\r\n",
        "test_df_masks = torch.tensor(test_df_masks)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZOboXJmcWza"
      },
      "source": [
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\r\n",
        "train_sampler = RandomSampler(train_data)\r\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\r\n",
        "\r\n",
        "dev_data = TensorDataset(dev_inputs, dev_masks, dev_labels)\r\n",
        "dev_sampler = SequentialSampler(dev_data)\r\n",
        "dev_dataloader = DataLoader(dev_data, sampler=dev_sampler, batch_size=batch_size)\r\n",
        "\r\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\r\n",
        "test_sampler = RandomSampler(test_data)\r\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\r\n",
        "\r\n",
        "test_df_data = TensorDataset(test_df_index, test_df_inputs, test_df_masks)\r\n",
        "test_df_sampler = RandomSampler(test_df_data)\r\n",
        "test_df_dataloader = DataLoader(test_df_data, sampler=test_df_sampler, batch_size=batch_size)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afbtrT3hg6sr"
      },
      "source": [
        "# 2. 모델 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rm8tkXDEg0h9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1cad7c4-822b-41c7-fb73-a8f7891b3645"
      },
      "source": [
        "# 디바이스 설정\r\n",
        "if torch.cuda.is_available():    \r\n",
        "    device = torch.device(\"cuda\")\r\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\r\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\r\n",
        "else:\r\n",
        "    device = torch.device(\"cpu\")\r\n",
        "    print('No GPU available, using the CPU instead.')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla V100-SXM2-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s40-YjZPKyft",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d07f87bb-36ea-4c01-9a60-d7c1c620d86e"
      },
      "source": [
        "model = ElectraForSequenceClassification.from_pretrained(TRAIN_MODEL, num_labels=8)\n",
        "model.cuda()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at google/electra-small-generator were not used when initializing ElectraForSequenceClassification: ['generator_predictions.LayerNorm.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.dense.weight', 'generator_predictions.dense.bias', 'generator_lm_head.weight', 'generator_lm_head.bias']\n",
            "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-small-generator and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ElectraForSequenceClassification(\n",
              "  (electra): ElectraModel(\n",
              "    (embeddings): ElectraEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 128)\n",
              "      (token_type_embeddings): Embedding(2, 128)\n",
              "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (embeddings_project): Linear(in_features=128, out_features=256, bias=True)\n",
              "    (encoder): ElectraEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
              "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): ElectraClassificationHead(\n",
              "    (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=256, out_features=8, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZwXlNqahGVe"
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\r\n",
        "                  lr = 2e-5, \r\n",
        "                  eps = 1e-8\r\n",
        "                )\r\n",
        "\r\n",
        "total_steps = len(train_dataloader) * epochs\r\n",
        "\r\n",
        "# 학습률을 조금씩 감소시키는 스케줄러 생성\r\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \r\n",
        "                                            num_warmup_steps = 0,\r\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9fpiLtphLEr"
      },
      "source": [
        "#학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSgXgK1thGYR"
      },
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\r\n",
        "from sklearn.metrics import confusion_matrix, classification_report\r\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\r\n",
        "import seaborn as sns\r\n",
        "\r\n",
        "# 정확도 계산 함수\r\n",
        "def flat_accuracy(preds, labels):\r\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\r\n",
        "    labels_flat = labels.flatten()\r\n",
        "\r\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\r\n",
        "\r\n",
        "# 시간 표시 함수\r\n",
        "def format_time(elapsed):\r\n",
        "\r\n",
        "    # 반올림\r\n",
        "    elapsed_rounded = int(round((elapsed)))\r\n",
        "    \r\n",
        "    # hh:mm:ss으로 형태 변경\r\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\r\n",
        "\r\n",
        "#평가함수\r\n",
        "def evaluate(true_list, pred_list):\r\n",
        "\r\n",
        "  accuracy = accuracy_score(true_list, pred_list)\r\n",
        "  precision = precision_score(true_list, pred_list, average=None)\r\n",
        "  recall = recall_score(true_list, pred_list, average=None)\r\n",
        "  micro_f1 = f1_score(true_list, pred_list, average='micro')\r\n",
        "\r\n",
        "  print(\"accuracy:{0:.4f}\".format(accuracy))\r\n",
        "  print('precision:\\t', ['%.4f' % v for v in precision])\r\n",
        "  print('recall:\\t\\t', ['%.4f' % v for v in recall])\r\n",
        "  print('micro_f1: %.6f' % micro_f1)\r\n",
        "\r\n",
        "  n_correct = [x for x, y in zip(true_list, pred_list) if x == y]\r\n",
        "  cnt_list = [0] * (8)\r\n",
        "  for cnt in n_correct:\r\n",
        "    if cnt==0:\r\n",
        "      cnt_list[cnt]+=1\r\n",
        "    elif cnt==1:\r\n",
        "      cnt_list[cnt]+=1\r\n",
        "    elif cnt==2:\r\n",
        "      cnt_list[cnt]+=1\r\n",
        "    elif cnt==3:\r\n",
        "      cnt_list[cnt]+=1\r\n",
        "    elif cnt==4:\r\n",
        "      cnt_list[cnt]+=1\r\n",
        "    elif cnt==5:\r\n",
        "      cnt_list[cnt]+=1\r\n",
        "    elif cnt==6:\r\n",
        "      cnt_list[cnt]+=1\r\n",
        "    elif cnt==7:\r\n",
        "      cnt_list[cnt]+=1\r\n",
        "\r\n",
        "  print(\"각 라벨 별 정답 cnt_list\",cnt_list)\r\n",
        "  return cnt_list\r\n",
        "\r\n",
        "def matrix_evaluate(true_list, pred_list, cnt_list):\r\n",
        "  target_names = ['anger', 'disgust', 'fear', 'joy', 'neutral', 'non-neutral', 'sadness', 'surprise'] \r\n",
        "\r\n",
        "  cm = confusion_matrix(true_list, pred_list)\r\n",
        "  sns.heatmap(cm, annot = True, fmt = 'd',cmap = 'Blues',) \r\n",
        "  print(classification_report(true_list, pred_list, digits=4, target_names=target_names))\r\n",
        " "
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYaXtdwbhGa2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ac4d586-e57b-4bc3-f3a4-54fdca1af49e"
      },
      "source": [
        "seed_val = 42\r\n",
        "random.seed(seed_val)\r\n",
        "np.random.seed(seed_val)\r\n",
        "torch.manual_seed(seed_val)\r\n",
        "torch.cuda.manual_seed_all(seed_val)\r\n",
        "\r\n",
        "model.zero_grad()\r\n",
        "\r\n",
        "for epoch_i in range(0, epochs):\r\n",
        "    \r\n",
        "    # ========================================\r\n",
        "    #               Training\r\n",
        "    # ========================================\r\n",
        "    print(\"\")\r\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\r\n",
        "    print('Training...')\r\n",
        "\r\n",
        "    t0 = time.time()\r\n",
        "    total_loss = 0\r\n",
        "    model.train()\r\n",
        "        \r\n",
        "    # 데이터로더에서 배치만큼 반복하여 가져옴\r\n",
        "    for step, batch in enumerate(train_dataloader):\r\n",
        "        if step % 500 == 0 and not step == 0:\r\n",
        "            elapsed = format_time(time.time() - t0)\r\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\r\n",
        "\r\n",
        "        batch = tuple(t.to(device) for t in batch)\r\n",
        "        b_input_ids, b_input_mask, b_labels = batch\r\n",
        "             \r\n",
        "        outputs = model(b_input_ids, \r\n",
        "                        token_type_ids=None, \r\n",
        "                        attention_mask=b_input_mask, \r\n",
        "                        labels=b_labels)\r\n",
        "\r\n",
        "        loss = outputs[0]\r\n",
        "        total_loss += loss.item()\r\n",
        "\r\n",
        "        loss.backward()\r\n",
        "\r\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\r\n",
        "        optimizer.step()\r\n",
        "        scheduler.step()\r\n",
        "        model.zero_grad()\r\n",
        "\r\n",
        "    # 평균 로스 계산\r\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \r\n",
        "\r\n",
        "    print(\"\")\r\n",
        "    print(\"  Average training loss: {0:.5f}\".format(avg_train_loss))\r\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\r\n",
        "        \r\n",
        "    # ========================================\r\n",
        "    #               Validation\r\n",
        "    # ========================================\r\n",
        "    print(\"\")\r\n",
        "    print(\"Running Validation...\")\r\n",
        "\r\n",
        "    t0 = time.time()\r\n",
        "    model.eval()\r\n",
        "\r\n",
        "    eval_accuracy, nb_eval_steps = 0, 0\r\n",
        "    pred_list, true_list = [], []\r\n",
        "\r\n",
        "    for batch in dev_dataloader:\r\n",
        "        batch = tuple(t.to(device) for t in batch)\r\n",
        "        b_input_ids, b_input_mask, b_labels = batch\r\n",
        "\r\n",
        "        with torch.no_grad():     \r\n",
        "            outputs = model(b_input_ids, \r\n",
        "                            token_type_ids=None, \r\n",
        "                            attention_mask=b_input_mask)\r\n",
        "        \r\n",
        "        logits = outputs[0]\r\n",
        "        logits = logits.detach().cpu().numpy()\r\n",
        "        label_ids = b_labels.to('cpu').numpy()\r\n",
        "     \r\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\r\n",
        "        eval_accuracy += tmp_eval_accuracy\r\n",
        "        nb_eval_steps += 1\r\n",
        "\r\n",
        "        pred_flat = np.argmax(logits, axis=1).flatten()\r\n",
        "        trues_flat = label_ids.flatten()\r\n",
        "        pred_list.extend(pred_flat)\r\n",
        "        true_list.extend(trues_flat)\r\n",
        "\r\n",
        "    print(\"  Accuracy: {0:.5f}\".format(eval_accuracy/nb_eval_steps))\r\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\r\n",
        "    cnt_list = evaluate(pred_list, true_list) # print results\r\n",
        "\r\n",
        "print(\"\")\r\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 20 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 1.61729\n",
            "  Training epcoh took: 0:00:16\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.47666\n",
            "  Validation took: 0:00:00\n",
            "accuracy:0.4796\n",
            "precision:\t ['0.0000', '0.0000', '0.0000', '0.3659', '0.9450', '0.1963', '0.0000', '0.0927']\n",
            "recall:\t\t ['0.0000', '0.0000', '0.0000', '0.2744', '0.5728', '0.2258', '0.0000', '0.7778']\n",
            "micro_f1: 0.479626\n",
            "각 라벨 별 정답 cnt_list [0, 0, 0, 45, 464, 42, 0, 14]\n",
            "\n",
            "======== Epoch 2 / 20 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 1.37205\n",
            "  Training epcoh took: 0:00:16\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.50051\n",
            "  Validation took: 0:00:00\n",
            "accuracy:0.5042\n",
            "precision:\t ['0.0000', '0.0000', '0.0000', '0.5854', '0.9369', '0.1028', '0.0000', '0.2649']\n",
            "recall:\t\t ['0.0000', '0.0000', '0.0000', '0.2892', '0.6021', '0.2472', '0.0000', '0.5263']\n",
            "micro_f1: 0.504244\n",
            "각 라벨 별 정답 cnt_list [0, 0, 0, 72, 460, 22, 0, 40]\n",
            "\n",
            "======== Epoch 3 / 20 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 1.29358\n",
            "  Training epcoh took: 0:00:15\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.52024\n",
            "  Validation took: 0:00:00\n",
            "accuracy:0.5246\n",
            "precision:\t ['0.0000', '0.0000', '0.0000', '0.5935', '0.9430', '0.2009', '0.0000', '0.2583']\n",
            "recall:\t\t ['0.0000', '0.0000', '0.0000', '0.3596', '0.6029', '0.3050', '0.0000', '0.5909']\n",
            "micro_f1: 0.524618\n",
            "각 라벨 별 정답 cnt_list [0, 0, 0, 73, 463, 43, 0, 39]\n",
            "\n",
            "======== Epoch 4 / 20 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 1.24360\n",
            "  Training epcoh took: 0:00:16\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.53131\n",
            "  Validation took: 0:00:00\n",
            "accuracy:0.5348\n",
            "precision:\t ['0.0000', '0.0000', '0.0000', '0.6016', '0.9022', '0.2477', '0.0323', '0.3841']\n",
            "recall:\t\t ['0.0000', '0.0000', '0.0000', '0.4066', '0.6467', '0.2849', '0.6667', '0.4754']\n",
            "micro_f1: 0.534805\n",
            "각 라벨 별 정답 cnt_list [0, 0, 0, 74, 443, 53, 2, 58]\n",
            "\n",
            "======== Epoch 5 / 20 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 1.22387\n",
            "  Training epcoh took: 0:00:16\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.52600\n",
            "  Validation took: 0:00:00\n",
            "accuracy:0.5306\n",
            "precision:\t ['0.0000', '0.0000', '0.0000', '0.6667', '0.8778', '0.2196', '0.1129', '0.3841']\n",
            "recall:\t\t ['0.0000', '0.0000', '0.0000', '0.3814', '0.6560', '0.2597', '0.7778', '0.5000']\n",
            "micro_f1: 0.530560\n",
            "각 라벨 별 정답 cnt_list [0, 0, 0, 82, 431, 47, 7, 58]\n",
            "\n",
            "======== Epoch 6 / 20 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 1.17958\n",
            "  Training epcoh took: 0:00:16\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.51575\n",
            "  Validation took: 0:00:00\n",
            "accuracy:0.5212\n",
            "precision:\t ['0.0000', '0.0000', '0.0000', '0.6504', '0.8310', '0.2336', '0.1452', '0.4437']\n",
            "recall:\t\t ['0.0000', '0.0000', '0.0000', '0.3791', '0.6811', '0.2404', '0.5294', '0.4685']\n",
            "micro_f1: 0.521222\n",
            "각 라벨 별 정답 cnt_list [0, 0, 0, 80, 408, 50, 9, 67]\n",
            "\n",
            "======== Epoch 7 / 20 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 1.14707\n",
            "  Training epcoh took: 0:00:16\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.53378\n",
            "  Validation took: 0:00:00\n",
            "accuracy:0.5374\n",
            "precision:\t ['0.0235', '0.0000', '0.0000', '0.6341', '0.9002', '0.2103', '0.1452', '0.3775']\n",
            "recall:\t\t ['0.6667', '0.0000', '0.0000', '0.3842', '0.6453', '0.2711', '0.4737', '0.5588']\n",
            "micro_f1: 0.537351\n",
            "각 라벨 별 정답 cnt_list [2, 0, 0, 78, 442, 45, 9, 57]\n",
            "\n",
            "======== Epoch 8 / 20 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 1.12050\n",
            "  Training epcoh took: 0:00:16\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.52518\n",
            "  Validation took: 0:00:00\n",
            "accuracy:0.5297\n",
            "precision:\t ['0.0353', '0.0000', '0.0000', '0.6260', '0.8697', '0.2009', '0.1774', '0.4172']\n",
            "recall:\t\t ['0.4286', '0.0000', '0.0000', '0.3929', '0.6590', '0.2575', '0.3667', '0.4846']\n",
            "micro_f1: 0.529711\n",
            "각 라벨 별 정답 cnt_list [3, 0, 0, 77, 427, 43, 11, 63]\n",
            "\n",
            "======== Epoch 9 / 20 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 1.09115\n",
            "  Training epcoh took: 0:00:16\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.52031\n",
            "  Validation took: 0:00:00\n",
            "accuracy:0.5272\n",
            "precision:\t ['0.0235', '0.0000', '0.0000', '0.6016', '0.8676', '0.2009', '0.1613', '0.4371']\n",
            "recall:\t\t ['0.3333', '0.0000', '0.0000', '0.3834', '0.6514', '0.2443', '0.5882', '0.5000']\n",
            "micro_f1: 0.527165\n",
            "각 라벨 별 정답 cnt_list [2, 0, 0, 74, 426, 43, 10, 66]\n",
            "\n",
            "======== Epoch 10 / 20 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 1.06639\n",
            "  Training epcoh took: 0:00:16\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.53587\n",
            "  Validation took: 0:00:00\n",
            "accuracy:0.5407\n",
            "precision:\t ['0.0706', '0.0000', '0.0000', '0.6341', '0.8941', '0.1822', '0.1935', '0.4172']\n",
            "recall:\t\t ['0.4286', '0.0000', '0.0000', '0.3920', '0.6572', '0.2617', '0.4000', '0.5339']\n",
            "micro_f1: 0.540747\n",
            "각 라벨 별 정답 cnt_list [6, 0, 0, 78, 439, 39, 12, 63]\n",
            "\n",
            "======== Epoch 11 / 20 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 1.05595\n",
            "  Training epcoh took: 0:00:15\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.52809\n",
            "  Validation took: 0:00:00\n",
            "accuracy:0.5340\n",
            "precision:\t ['0.0824', '0.0000', '0.0000', '0.6423', '0.8635', '0.1916', '0.1935', '0.4371']\n",
            "recall:\t\t ['0.4375', '0.0000', '0.0000', '0.3930', '0.6709', '0.2384', '0.3871', '0.5238']\n",
            "micro_f1: 0.533956\n",
            "각 라벨 별 정답 cnt_list [7, 0, 0, 79, 424, 41, 12, 66]\n",
            "\n",
            "======== Epoch 12 / 20 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 1.03595\n",
            "  Training epcoh took: 0:00:16\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.51771\n",
            "  Validation took: 0:00:00\n",
            "accuracy:0.5195\n",
            "precision:\t ['0.1412', '0.0000', '0.0000', '0.5935', '0.8086', '0.2056', '0.2097', '0.4834']\n",
            "recall:\t\t ['0.4286', '0.0000', '0.0000', '0.4078', '0.6810', '0.2256', '0.3714', '0.4620']\n",
            "micro_f1: 0.519525\n",
            "각 라벨 별 정답 cnt_list [12, 0, 0, 73, 397, 44, 13, 73]\n",
            "\n",
            "======== Epoch 13 / 20 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 1.01774\n",
            "  Training epcoh took: 0:00:15\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.52018\n",
            "  Validation took: 0:00:00\n",
            "accuracy:0.5221\n",
            "precision:\t ['0.1412', '0.0000', '0.0000', '0.5854', '0.8187', '0.2056', '0.2097', '0.4768']\n",
            "recall:\t\t ['0.4000', '0.0000', '0.0000', '0.4337', '0.6689', '0.2328', '0.3171', '0.4768']\n",
            "micro_f1: 0.522071\n",
            "각 라벨 별 정답 cnt_list [12, 0, 0, 72, 402, 44, 13, 72]\n",
            "\n",
            "======== Epoch 14 / 20 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.99914\n",
            "  Training epcoh took: 0:00:15\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.51771\n",
            "  Validation took: 0:00:00\n",
            "accuracy:0.5195\n",
            "precision:\t ['0.2000', '0.0000', '0.0000', '0.6260', '0.8106', '0.1729', '0.2258', '0.4570']\n",
            "recall:\t\t ['0.4722', '0.0000', '0.0000', '0.3889', '0.6723', '0.2270', '0.2745', '0.5000']\n",
            "micro_f1: 0.519525\n",
            "각 라벨 별 정답 cnt_list [17, 0, 0, 77, 398, 37, 14, 69]\n",
            "\n",
            "======== Epoch 15 / 20 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.98519\n",
            "  Training epcoh took: 0:00:15\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.50253\n",
            "  Validation took: 0:00:00\n",
            "accuracy:0.5051\n",
            "precision:\t ['0.2000', '0.0000', '0.0000', '0.6260', '0.7454', '0.2056', '0.2258', '0.5099']\n",
            "recall:\t\t ['0.4857', '0.0000', '0.0000', '0.3812', '0.6740', '0.2211', '0.3500', '0.4843']\n",
            "micro_f1: 0.505093\n",
            "각 라벨 별 정답 cnt_list [17, 0, 0, 77, 366, 44, 14, 77]\n",
            "\n",
            "======== Epoch 16 / 20 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.98945\n",
            "  Training epcoh took: 0:00:16\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.51278\n",
            "  Validation took: 0:00:00\n",
            "accuracy:0.5144\n",
            "precision:\t ['0.2118', '0.0000', '0.0000', '0.6098', '0.7862', '0.2103', '0.2258', '0.4503']\n",
            "recall:\t\t ['0.4286', '0.0000', '0.0000', '0.3968', '0.6760', '0.2174', '0.3684', '0.5191']\n",
            "micro_f1: 0.514431\n",
            "각 라벨 별 정답 cnt_list [18, 0, 0, 75, 386, 45, 14, 68]\n",
            "\n",
            "======== Epoch 17 / 20 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.95473\n",
            "  Training epcoh took: 0:00:15\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.50949\n",
            "  Validation took: 0:00:00\n",
            "accuracy:0.5110\n",
            "precision:\t ['0.1765', '0.0000', '0.0000', '0.6016', '0.7821', '0.2150', '0.2258', '0.4570']\n",
            "recall:\t\t ['0.4286', '0.0000', '0.0000', '0.4066', '0.6713', '0.2212', '0.3684', '0.4825']\n",
            "micro_f1: 0.511036\n",
            "각 라벨 별 정답 cnt_list [15, 0, 0, 74, 384, 46, 14, 69]\n",
            "\n",
            "======== Epoch 18 / 20 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.94529\n",
            "  Training epcoh took: 0:00:16\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.51316\n",
            "  Validation took: 0:00:00\n",
            "accuracy:0.5136\n",
            "precision:\t ['0.1882', '0.0000', '0.0000', '0.6016', '0.7984', '0.1869', '0.2258', '0.4570']\n",
            "recall:\t\t ['0.4103', '0.0000', '0.0000', '0.4134', '0.6655', '0.2128', '0.3684', '0.4759']\n",
            "micro_f1: 0.513582\n",
            "각 라벨 별 정답 cnt_list [16, 0, 0, 74, 392, 40, 14, 69]\n",
            "\n",
            "======== Epoch 19 / 20 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.94649\n",
            "  Training epcoh took: 0:00:15\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.50620\n",
            "  Validation took: 0:00:00\n",
            "accuracy:0.5076\n",
            "precision:\t ['0.1882', '0.0000', '0.0000', '0.6016', '0.7739', '0.2103', '0.2258', '0.4570']\n",
            "recall:\t\t ['0.4000', '0.0000', '0.0000', '0.4044', '0.6750', '0.2174', '0.3684', '0.4694']\n",
            "micro_f1: 0.507640\n",
            "각 라벨 별 정답 cnt_list [16, 0, 0, 74, 380, 45, 14, 69]\n",
            "\n",
            "======== Epoch 20 / 20 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.94495\n",
            "  Training epcoh took: 0:00:16\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.51151\n",
            "  Validation took: 0:00:00\n",
            "accuracy:0.5119\n",
            "precision:\t ['0.1882', '0.0000', '0.0000', '0.6016', '0.7841', '0.2103', '0.2258', '0.4570']\n",
            "recall:\t\t ['0.4103', '0.0000', '0.0000', '0.4088', '0.6696', '0.2217', '0.3684', '0.4859']\n",
            "micro_f1: 0.511885\n",
            "각 라벨 별 정답 cnt_list [16, 0, 0, 74, 385, 45, 14, 69]\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JKfoqdTbni0"
      },
      "source": [
        "# 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KB_Nvm-16ohw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcdeaa2a-985b-486b-97e5-74c450fa8452"
      },
      "source": [
        "#시작 시간 설정\r\n",
        "t0 = time.time()\r\n",
        "\r\n",
        "# 평가모드로 변경\r\n",
        "model.eval()\r\n",
        "\r\n",
        "# 변수 초기화\r\n",
        "f1_score_avg = []\r\n",
        "pred_list, true_list = [], []\r\n",
        "eval_loss, eval_accuracy = 0, 0\r\n",
        "nb_eval_steps, nb_eval_examples = 0, 0\r\n",
        "\r\n",
        "for step, batch in enumerate(test_dataloader):\r\n",
        "    if step % 100 == 0 and not step == 0:\r\n",
        "        elapsed = format_time(time.time() - t0)\r\n",
        "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\r\n",
        "\r\n",
        "    batch = tuple(t.to(device) for t in batch)\r\n",
        "    b_input_ids, b_input_mask, b_labels = batch\r\n",
        "    \r\n",
        "    # 그래디언트 계산 안함\r\n",
        "    with torch.no_grad():     \r\n",
        "        # Forward 수행\r\n",
        "        outputs = model(b_input_ids, \r\n",
        "                        token_type_ids=None, \r\n",
        "                        attention_mask=b_input_mask)\r\n",
        "    \r\n",
        "    logits = outputs[0]\r\n",
        "\r\n",
        "    # CPU로 데이터 이동\r\n",
        "    logits = logits.detach().cpu().numpy()\r\n",
        "    label_ids = b_labels.to('cpu').numpy()\r\n",
        "\r\n",
        "    pred_flat = np.argmax(logits, axis=1).flatten()\r\n",
        "    trues_flat = label_ids.flatten()\r\n",
        "    pred_list.extend(pred_flat)\r\n",
        "    true_list.extend(trues_flat)\r\n",
        "    \r\n",
        "    # 출력 로짓과 라벨을 비교하여 정확도 계산\r\n",
        "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\r\n",
        "    eval_accuracy += tmp_eval_accuracy\r\n",
        "    nb_eval_steps += 1\r\n",
        "\r\n",
        "print(\"\")\r\n",
        "print(\"  Accuracy: {0:.5f}\".format(eval_accuracy/nb_eval_steps))\r\n",
        "print(\"Test took: {:}\".format(format_time(time.time() - t0)))\r\n",
        "print(\"Emotion accuracy\")\r\n",
        "cnt_list = evaluate(pred_list, true_list) # print results\r\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  Accuracy: 0.57055\n",
            "Test took: 0:00:01\n",
            "Emotion accuracy\n",
            "accuracy:0.5687\n",
            "precision:\t ['0.1988', '0.0000', '0.0000', '0.6349', '0.7941', '0.3124', '0.2941', '0.4580']\n",
            "recall:\t\t ['0.4051', '0.0000', '0.0000', '0.4595', '0.7422', '0.3301', '0.3165', '0.4411']\n",
            "micro_f1: 0.568741\n",
            "각 라벨 별 정답 cnt_list [32, 0, 0, 193, 1022, 169, 25, 131]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "fjepMWfRsp6C",
        "outputId": "62785c96-df79-4afc-f7d3-78cfab34c06b"
      },
      "source": [
        "target_names = ['anger', 'disgust', 'fear', 'joy', 'neutral', 'non-neutral', 'sadness', 'surprise']\r\n",
        "plt.bar(target_names,cnt_list)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 8 artists>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "_LzFXZcCsmXF",
        "outputId": "83b2e3ed-0d43-4cde-c82f-038cfbc9a8fd"
      },
      "source": [
        "matrix_evaluate(pred_list, true_list, cnt_list)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger     0.1988    0.4051    0.2667        79\n",
            "     disgust     0.0000    0.0000    0.0000         0\n",
            "        fear     0.0000    0.0000    0.0000         0\n",
            "         joy     0.6349    0.4595    0.5331       420\n",
            "     neutral     0.7941    0.7422    0.7673      1377\n",
            " non-neutral     0.3124    0.3301    0.3210       512\n",
            "     sadness     0.2941    0.3165    0.3049        79\n",
            "    surprise     0.4580    0.4411    0.4494       297\n",
            "\n",
            "    accuracy                         0.5687      2764\n",
            "   macro avg     0.3365    0.3368    0.3303      2764\n",
            "weighted avg     0.6133    0.5687    0.5873      2764\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_GsRFFbhSwj"
      },
      "source": [
        "# test 결과물"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_S78N33ohWWl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ac22245-9400-443f-aad3-4ab90b3ed353"
      },
      "source": [
        "tmp_test_dataloader = DataLoader(test_df_data, sampler=test_df_sampler, batch_size=1)\r\n",
        "test_result = test_df.copy(deep = True)\r\n",
        "test_result = test_result.drop(columns = ['i_dialog', 'i_utterance', 'speaker'])\r\n",
        "test_result['Predicted'] = 'default'\r\n",
        "classes = [0,1,2,3,4,5,6,7]\r\n",
        "\r\n",
        "encoder = LabelEncoder()\r\n",
        "classes = emotions\r\n",
        "encoder.fit(classes)\r\n",
        "classes = encoder.transform(classes)\r\n",
        "\r\n",
        "#시작 시간 설정\r\n",
        "t0 = time.time()\r\n",
        "\r\n",
        "# 평가모드로 변경\r\n",
        "model.eval()\r\n",
        "\r\n",
        "# 변수 초기화\r\n",
        "nb_eval_steps, nb_eval_examples = 0, 0\r\n",
        "\r\n",
        "# 데이터로더에서 배치만큼 반복하여 가져옴\r\n",
        "for step, batch in enumerate(tmp_test_dataloader):\r\n",
        "    # 경과 정보 표시\r\n",
        "    if step % 100 == 0 and not step == 0:\r\n",
        "        elapsed = format_time(time.time() - t0)\r\n",
        "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(tmp_test_dataloader), elapsed))\r\n",
        "\r\n",
        "    # 배치를 GPU에 넣음\r\n",
        "    batch = tuple(t.to(device) for t in batch)\r\n",
        "    \r\n",
        "    # 배치에서 데이터 추출\r\n",
        "    b_index, b_input_ids, b_input_mask = batch\r\n",
        "    \r\n",
        "    # 그래디언트 계산 안함\r\n",
        "    with torch.no_grad():     \r\n",
        "        # Forward 수행\r\n",
        "        outputs = model(b_input_ids, \r\n",
        "                        token_type_ids=None, \r\n",
        "                        attention_mask=b_input_mask)\r\n",
        "    \r\n",
        "    # 로스 구함\r\n",
        "    logits = outputs[0]\r\n",
        "\r\n",
        "    # CPU로 데이터 이동\r\n",
        "    logits = logits.detach().cpu().numpy()\r\n",
        "    idx = b_index.item()\r\n",
        "    test_result['Predicted'][idx] = encoder.classes_[np.argmax(logits)]\r\n",
        "    \r\n",
        "\r\n",
        "    nb_eval_steps += 1\r\n",
        "\r\n",
        "print(\"\")\r\n",
        "print(\"Test took: {:}\".format(format_time(time.time() - t0)))\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:47: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch   100  of  1,623.    Elapsed: 0:00:01.\n",
            "  Batch   200  of  1,623.    Elapsed: 0:00:02.\n",
            "  Batch   300  of  1,623.    Elapsed: 0:00:04.\n",
            "  Batch   400  of  1,623.    Elapsed: 0:00:05.\n",
            "  Batch   500  of  1,623.    Elapsed: 0:00:06.\n",
            "  Batch   600  of  1,623.    Elapsed: 0:00:07.\n",
            "  Batch   700  of  1,623.    Elapsed: 0:00:09.\n",
            "  Batch   800  of  1,623.    Elapsed: 0:00:10.\n",
            "  Batch   900  of  1,623.    Elapsed: 0:00:11.\n",
            "  Batch 1,000  of  1,623.    Elapsed: 0:00:12.\n",
            "  Batch 1,100  of  1,623.    Elapsed: 0:00:13.\n",
            "  Batch 1,200  of  1,623.    Elapsed: 0:00:14.\n",
            "  Batch 1,300  of  1,623.    Elapsed: 0:00:16.\n",
            "  Batch 1,400  of  1,623.    Elapsed: 0:00:17.\n",
            "  Batch 1,500  of  1,623.    Elapsed: 0:00:18.\n",
            "  Batch 1,600  of  1,623.    Elapsed: 0:00:19.\n",
            "\n",
            "Test took: 0:00:19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtVGAJ3QhWY6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ccba89f-191e-433e-9aee-bf5636d6daf8"
      },
      "source": [
        "test_result['Predicted']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0           neutral\n",
              "1               joy\n",
              "2             anger\n",
              "3           neutral\n",
              "4       non-neutral\n",
              "           ...     \n",
              "1618        neutral\n",
              "1619            joy\n",
              "1620        neutral\n",
              "1621        neutral\n",
              "1622          anger\n",
              "Name: Predicted, Length: 1623, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PmG3cdAhWbk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "f7f7cb03-252f-49cf-a8c9-e85d3cb79b49"
      },
      "source": [
        "test_result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>utterance</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Alright, whadyou do with him?</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Oh! You're awake!</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Then you gotta come clean with Ma! This is not...</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Yeah, but this is</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>I don't wanna hear it! Now go to my room!</td>\n",
              "      <td>non-neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1618</th>\n",
              "      <td>1618</td>\n",
              "      <td>Nooo.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1619</th>\n",
              "      <td>1619</td>\n",
              "      <td>Hi, Kate!</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1620</th>\n",
              "      <td>1620</td>\n",
              "      <td>Hi, Lauren.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1621</th>\n",
              "      <td>1621</td>\n",
              "      <td>Hi, Lauren.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1622</th>\n",
              "      <td>1622</td>\n",
              "      <td>Hi, pig!</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1623 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        id                                          utterance    Predicted\n",
              "0        0                      Alright, whadyou do with him?      neutral\n",
              "1        1                                  Oh! You're awake!          joy\n",
              "2        2  Then you gotta come clean with Ma! This is not...        anger\n",
              "3        3                                  Yeah, but this is      neutral\n",
              "4        4          I don't wanna hear it! Now go to my room!  non-neutral\n",
              "...    ...                                                ...          ...\n",
              "1618  1618                                              Nooo.      neutral\n",
              "1619  1619                                          Hi, Kate!          joy\n",
              "1620  1620                                        Hi, Lauren.      neutral\n",
              "1621  1621                                        Hi, Lauren.      neutral\n",
              "1622  1622                                           Hi, pig!        anger\n",
              "\n",
              "[1623 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2qTHzzshGhq"
      },
      "source": [
        "test_result.drop(labels='utterance', axis=\"columns\", inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_lLlP__hacf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "6c07fb17-2d2f-405b-b038-663512b88260"
      },
      "source": [
        "test_csv = test_result.to_csv('submission_bert_uncase_20.csv', columns=['id', 'Predicted'], index=False)\r\n",
        "from google.colab import files\r\n",
        "\r\n",
        "files.download('submission_bert_uncase_20.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_7d694564-b55f-4b5a-8c53-65b1cb6d9270\", \"submission_bert_uncase_20.csv\", 20720)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}