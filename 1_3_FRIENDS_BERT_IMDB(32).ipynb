{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1-3. FRIENDS_BERT_IMDB(32).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1UhC_svCNScndorgU2jl1jtVlfpFVcm3B",
      "authorship_tag": "ABX9TyMar3DsyIxxtiIwGjAXCKW7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cc4ead7775324fac9734cd15e1367936": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6464326c6e4d4915b315d3d9ec2e858f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b04577e9cccb4dc3aefba784dd429e52",
              "IPY_MODEL_e9588efba99a4758af2303ed7c610151"
            ]
          }
        },
        "6464326c6e4d4915b315d3d9ec2e858f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b04577e9cccb4dc3aefba784dd429e52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f7f7bba5e0084005a691624a6640a4ae",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_81d699c626704ca9bafe75fd63a0a97e"
          }
        },
        "e9588efba99a4758af2303ed7c610151": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e88e61c023444c1c8d3379d898df0f5b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 308kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_be53f973ad6a4a0daf3f077e1f763d6f"
          }
        },
        "f7f7bba5e0084005a691624a6640a4ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "81d699c626704ca9bafe75fd63a0a97e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e88e61c023444c1c8d3379d898df0f5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "be53f973ad6a4a0daf3f077e1f763d6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "13ed923a528641178b4bb701471f99c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c61061d0178d43ee98a81b12fffd941c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ed4b84f8558545adbd1326dfbde89d26",
              "IPY_MODEL_e5ac9ec689ae45aab273f47b01ac31c1"
            ]
          }
        },
        "c61061d0178d43ee98a81b12fffd941c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ed4b84f8558545adbd1326dfbde89d26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_638f78e48a3442edb832795a947ea99a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_77b49e6ba1cb49478c6a5513c92951bd"
          }
        },
        "e5ac9ec689ae45aab273f47b01ac31c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_451592c5c0d645bead359ce5eb8e2456",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:18&lt;00:00, 23.0B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_818eb7bc16cf4807a16983e81a19e7b1"
          }
        },
        "638f78e48a3442edb832795a947ea99a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "77b49e6ba1cb49478c6a5513c92951bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "451592c5c0d645bead359ce5eb8e2456": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "818eb7bc16cf4807a16983e81a19e7b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5590e94f2b97466e9aa1fe3251a4c627": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5cdab5c414ae43889dbe4f3f47df45f1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a73624af91dd471a8cb4adf315e95cfe",
              "IPY_MODEL_1e4dd05f70e74cef9fb051048dba4a6a"
            ]
          }
        },
        "5cdab5c414ae43889dbe4f3f47df45f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a73624af91dd471a8cb4adf315e95cfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ff8b4b74424e4cc6bb8ac29f491c8e29",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5a1565762b1349c19d2087cf9067a139"
          }
        },
        "1e4dd05f70e74cef9fb051048dba4a6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e35a419193a44a03a11cd601ee3e5e6d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:06&lt;00:00, 66.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ccbbeedaf78b4312a8d61a51c3369858"
          }
        },
        "ff8b4b74424e4cc6bb8ac29f491c8e29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5a1565762b1349c19d2087cf9067a139": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e35a419193a44a03a11cd601ee3e5e6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ccbbeedaf78b4312a8d61a51c3369858": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sweetbaer03/EN_Sentiment-Analysis/blob/main/1_3_FRIENDS_BERT_IMDB(32).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tb0PNX9aZi0p"
      },
      "source": [
        "**FRIENDS Sentiment Analysis**\r\n",
        "\r\n",
        "\r\n",
        "Bert 모델 사용 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKkEByjh5y_h",
        "outputId": "fa58f7a0-ff0e-4bea-b4f2-989df714a45b"
      },
      "source": [
        "#transformers 설치(colab 사용시)\r\n",
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/0c/7d5950fcd80b029be0a8891727ba21e0cd27692c407c51261c3c921f6da3/transformers-4.1.1-py3-none-any.whl (1.5MB)\n",
            "\r\u001b[K     |▏                               | 10kB 14.0MB/s eta 0:00:01\r\u001b[K     |▍                               | 20kB 12.1MB/s eta 0:00:01\r\u001b[K     |▋                               | 30kB 8.7MB/s eta 0:00:01\r\u001b[K     |▉                               | 40kB 7.6MB/s eta 0:00:01\r\u001b[K     |█                               | 51kB 4.4MB/s eta 0:00:01\r\u001b[K     |█▎                              | 61kB 5.0MB/s eta 0:00:01\r\u001b[K     |█▌                              | 71kB 5.1MB/s eta 0:00:01\r\u001b[K     |█▊                              | 81kB 5.4MB/s eta 0:00:01\r\u001b[K     |██                              | 92kB 5.7MB/s eta 0:00:01\r\u001b[K     |██▏                             | 102kB 5.8MB/s eta 0:00:01\r\u001b[K     |██▍                             | 112kB 5.8MB/s eta 0:00:01\r\u001b[K     |██▋                             | 122kB 5.8MB/s eta 0:00:01\r\u001b[K     |██▉                             | 133kB 5.8MB/s eta 0:00:01\r\u001b[K     |███                             | 143kB 5.8MB/s eta 0:00:01\r\u001b[K     |███▎                            | 153kB 5.8MB/s eta 0:00:01\r\u001b[K     |███▌                            | 163kB 5.8MB/s eta 0:00:01\r\u001b[K     |███▊                            | 174kB 5.8MB/s eta 0:00:01\r\u001b[K     |████                            | 184kB 5.8MB/s eta 0:00:01\r\u001b[K     |████▏                           | 194kB 5.8MB/s eta 0:00:01\r\u001b[K     |████▎                           | 204kB 5.8MB/s eta 0:00:01\r\u001b[K     |████▌                           | 215kB 5.8MB/s eta 0:00:01\r\u001b[K     |████▊                           | 225kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████                           | 235kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 245kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 256kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 266kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 276kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 286kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 296kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 307kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 317kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 327kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 337kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 348kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 358kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 368kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 378kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 389kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 399kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 409kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 419kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████                       | 430kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 440kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 450kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 460kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 471kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 481kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 491kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 501kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 512kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 522kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 532kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 542kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 552kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 563kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 573kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 583kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 593kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 604kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 614kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 624kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 634kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 645kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 655kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 665kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 675kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 686kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 696kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 706kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 716kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 727kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 737kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 747kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 757kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 768kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 778kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 788kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 798kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 808kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 819kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 829kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 839kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 849kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 860kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 870kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 880kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 890kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 901kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 911kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 921kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 931kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 942kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 952kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 962kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 972kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 983kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 993kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.0MB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.0MB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.0MB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.0MB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.0MB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.1MB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.1MB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.1MB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.1MB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.1MB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.1MB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.1MB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.1MB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.1MB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.1MB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.2MB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.2MB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.2MB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.2MB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.2MB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.2MB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.2MB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.2MB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.2MB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.2MB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.3MB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.3MB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.3MB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.3MB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.3MB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.3MB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.3MB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.3MB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.3MB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.4MB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.4MB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.4MB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.4MB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.4MB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.4MB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.4MB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.4MB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.4MB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.4MB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.5MB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.5MB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.5MB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.5MB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.5MB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.5MB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.5MB 5.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 44.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 42.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=9e53d867e974afb30b664085ef73d368583a4dc9f07e3f496d6ae4e64014b354\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4L8v9ECIs-k"
      },
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import datetime\n",
        "import json\n",
        "import re\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from transformers import ElectraTokenizer, ElectraForSequenceClassification\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIZWo5sLZptB"
      },
      "source": [
        "# 데이터처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7b2jnOOJeaSe",
        "outputId": "7bcc55c3-42ca-414a-f90e-70520724b438"
      },
      "source": [
        "!git clone https://github.com/sweetbaer03/EN_Sentiment-Analysis.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'EN_Sentiment-Analysis'...\n",
            "remote: Enumerating objects: 44, done.\u001b[K\n",
            "remote: Counting objects: 100% (44/44), done.\u001b[K\n",
            "remote: Compressing objects: 100% (41/41), done.\u001b[K\n",
            "remote: Total 44 (delta 18), reused 6 (delta 1), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (44/44), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLlzf3XhZsG3"
      },
      "source": [
        "#파라미터 수정\r\n",
        "MAX_LEN = 85\r\n",
        "batch_size = 32\r\n",
        "epochs = 20\r\n",
        "\r\n",
        "TOKEN_MODEL = 'bert-base-uncased'\r\n",
        "TRAIN_MODEL = 'bert-base-uncased'\r\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jxeGmpdZviu"
      },
      "source": [
        "## 1.1 프렌즈 / 캐글 테스트 데이터"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dve0WGvuKyaZ"
      },
      "source": [
        "def jsonToDf(file_name):\n",
        "  with open(file_name, encoding = 'utf-8', mode = 'r') as file:\n",
        "    json_array = json.load(file)\n",
        "  \n",
        "  result = pd.DataFrame.from_dict(json_array[0])\n",
        "\n",
        "  is_first = True\n",
        "  for array in json_array:\n",
        "    if is_first:\n",
        "      is_first = False\n",
        "      continue\n",
        "    \n",
        "    temp_df = pd.DataFrame.from_dict(array)\n",
        "    result = result.append(temp_df, ignore_index = True)\n",
        "\n",
        "  return result"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBb5PrmqesC-"
      },
      "source": [
        "train_data = jsonToDf('EN_Sentiment-Analysis/data_in/friends_train.json')\r\n",
        "dev_data   = jsonToDf('EN_Sentiment-Analysis/data_in/friends_dev.json')\r\n",
        "test_data  = jsonToDf('EN_Sentiment-Analysis/data_in/friends_test.json')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGBQ3XLFUMXI"
      },
      "source": [
        "#합치기 위해 포멧 통일\r\n",
        "train_data.drop(labels=['speaker','annotation'], axis=\"columns\", inplace=True)\r\n",
        "dev_data.drop(labels=['speaker','annotation'], axis=\"columns\", inplace=True)\r\n",
        "test_data.drop(labels=['speaker','annotation'], axis=\"columns\", inplace=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtQIjp9yesD7"
      },
      "source": [
        "emotions = train_data['emotion'].values"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4L8yxjEZ6TN"
      },
      "source": [
        "**캐글** 테스트 데이터"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdnQa_w-Z-Ep"
      },
      "source": [
        "test_df = pd.read_csv('EN_Sentiment-Analysis/data_in/en_data.csv')#, encoding = 'unicode_escape')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "YFJzryJVZ-HR",
        "outputId": "3bfafc0c-c269-4d85-f32b-7e47bbaec3e5"
      },
      "source": [
        "test_df"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>i_dialog</th>\n",
              "      <th>i_utterance</th>\n",
              "      <th>speaker</th>\n",
              "      <th>utterance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Phoebe</td>\n",
              "      <td>Alright, whadyou do with him?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Monica</td>\n",
              "      <td>Oh! You're awake!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>Joey</td>\n",
              "      <td>Then you gotta come clean with Ma! This is not...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Mr. Tribbiani</td>\n",
              "      <td>Yeah, but this is</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>Joey</td>\n",
              "      <td>I don't wanna hear it! Now go to my room!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1618</th>\n",
              "      <td>1618</td>\n",
              "      <td>150</td>\n",
              "      <td>14</td>\n",
              "      <td>Joey</td>\n",
              "      <td>Nooo.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1619</th>\n",
              "      <td>1619</td>\n",
              "      <td>150</td>\n",
              "      <td>15</td>\n",
              "      <td>Lauren</td>\n",
              "      <td>Hi, Kate!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1620</th>\n",
              "      <td>1620</td>\n",
              "      <td>150</td>\n",
              "      <td>16</td>\n",
              "      <td>Kate</td>\n",
              "      <td>Hi, Lauren.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1621</th>\n",
              "      <td>1621</td>\n",
              "      <td>150</td>\n",
              "      <td>17</td>\n",
              "      <td>Joey</td>\n",
              "      <td>Hi, Lauren.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1622</th>\n",
              "      <td>1622</td>\n",
              "      <td>150</td>\n",
              "      <td>18</td>\n",
              "      <td>Lauren</td>\n",
              "      <td>Hi, pig!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1623 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ...                                          utterance\n",
              "0        0  ...                      Alright, whadyou do with him?\n",
              "1        1  ...                                  Oh! You're awake!\n",
              "2        2  ...  Then you gotta come clean with Ma! This is not...\n",
              "3        3  ...                                  Yeah, but this is\n",
              "4        4  ...          I don't wanna hear it! Now go to my room!\n",
              "...    ...  ...                                                ...\n",
              "1618  1618  ...                                              Nooo.\n",
              "1619  1619  ...                                          Hi, Kate!\n",
              "1620  1620  ...                                        Hi, Lauren.\n",
              "1621  1621  ...                                        Hi, Lauren.\n",
              "1622  1622  ...                                           Hi, pig!\n",
              "\n",
              "[1623 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3_Pd54TaBP5"
      },
      "source": [
        "### 프랜즈 및 캐글테스트 마스크 처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYWmejP_aDaj"
      },
      "source": [
        "프랜즈 데이터 마스크"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZM1ZPu__Z-Je",
        "outputId": "1cb0a8b1-1d41-4639-f8eb-3320c59353e0"
      },
      "source": [
        "print(train_data.shape)\r\n",
        "print(dev_data.shape)\r\n",
        "print(test_data.shape)\r\n",
        "print(test_df.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10561, 2)\n",
            "(1178, 2)\n",
            "(2764, 2)\n",
            "(1623, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYefryyFaFsl"
      },
      "source": [
        "def cleaning1(str):\r\n",
        "    replaceAll= str\r\n",
        "    only_english = re.sub('\\x92', '\\'', replaceAll)\r\n",
        "    return only_english\r\n",
        "\r\n",
        "\r\n",
        "def getInputsAndLabels(dataset):\r\n",
        "  data = dataset.copy(deep=True)\r\n",
        "\r\n",
        "  utterances = data['utterance']\r\n",
        "  utterances = [\"[CLS] \" + str(cleaning1(utterance)) + \" [SEP]\" for utterance in utterances]#이거다!\r\n",
        "  \r\n",
        "  encoder = LabelEncoder()\r\n",
        "  labels = data['emotion'].values\r\n",
        "  encoder.fit(labels)\r\n",
        "  labels = encoder.transform(labels)\r\n",
        "\r\n",
        "  tokenizer = BertTokenizer.from_pretrained(TOKEN_MODEL, do_lower_case=False)\r\n",
        "  tokenized_texts = [tokenizer.tokenize(utterance) for utterance in utterances]\r\n",
        "\r\n",
        "  input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\r\n",
        "  input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\r\n",
        "\r\n",
        "  attention_masks = []\r\n",
        "  for seq in input_ids:\r\n",
        "      seq_mask = [float(i>0) for i in seq]\r\n",
        "      attention_masks.append(seq_mask)\r\n",
        "\r\n",
        "  return input_ids, labels, attention_masks\r\n",
        "\r\n",
        "\r\n",
        "def getInputsFromTest(dataset):\r\n",
        "  data = dataset.copy(deep=True)\r\n",
        "\r\n",
        "  utterances = data['utterance']\r\n",
        "  utterances = [\"[CLS] \" + str(cleaning1(utterance)) + \" [SEP]\" for utterance in utterances]#이거다!\r\n",
        "  \r\n",
        "  tokenizer = BertTokenizer.from_pretrained(TOKEN_MODEL, do_lower_case=False)\r\n",
        "  tokenized_texts = [tokenizer.tokenize(utterance) for utterance in utterances]\r\n",
        "\r\n",
        "  input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\r\n",
        "  input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\r\n",
        "\r\n",
        "  attention_masks = []\r\n",
        "  for seq in input_ids:\r\n",
        "      seq_mask = [float(i>0) for i in seq]\r\n",
        "      attention_masks.append(seq_mask)\r\n",
        "\r\n",
        "  return input_ids, attention_masks\r\n",
        "\r\n",
        "\r\n",
        "def getIndex(dataset):\r\n",
        "  data = dataset.copy(deep = True)\r\n",
        "  input_index = data.id.tolist()\r\n",
        "  return torch.tensor(input_index)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "cc4ead7775324fac9734cd15e1367936",
            "6464326c6e4d4915b315d3d9ec2e858f",
            "b04577e9cccb4dc3aefba784dd429e52",
            "e9588efba99a4758af2303ed7c610151",
            "f7f7bba5e0084005a691624a6640a4ae",
            "81d699c626704ca9bafe75fd63a0a97e",
            "e88e61c023444c1c8d3379d898df0f5b",
            "be53f973ad6a4a0daf3f077e1f763d6f"
          ]
        },
        "id": "FnYXHQddaFKq",
        "outputId": "d63e8d22-ea5a-41c2-a9b6-ce1a7346f710"
      },
      "source": [
        "train_inputs1, train_labels1, train_masks1 = getInputsAndLabels(train_data)\r\n",
        "dev_inputs, dev_labels, dev_masks = getInputsAndLabels(dev_data)\r\n",
        "test_inputs, test_labels, test_masks = getInputsAndLabels(test_data)\r\n",
        "test_df_inputs, test_df_masks = getInputsFromTest(test_df)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cc4ead7775324fac9734cd15e1367936",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bccL-4SyaYPk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f6c2e13-4821-4300-cb32-56f4355a0a3b"
      },
      "source": [
        "print('전체 프랜즈 학  습 데이터의 개수: {}'.format(len(train_inputs1)))\r\n",
        "print('전체 프랜즈 라  벨 데이터의 개수: {}'.format(len(train_labels1)))\r\n",
        "print('전체 프랜즈 마스크 데이터의 개수: {}'.format(len(train_masks1)))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 프랜즈 학  습 데이터의 개수: 10561\n",
            "전체 프랜즈 라  벨 데이터의 개수: 10561\n",
            "전체 프랜즈 마스크 데이터의 개수: 10561\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKJmHndEaYSM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2df8f73e-f471-4b36-9d9c-6a3d5f6ea46d"
      },
      "source": [
        "print('전체 프랜즈 dev학  습 데이터의 개수: {}'.format(len(dev_inputs)))\r\n",
        "print('전체 프랜즈 dev라  벨 데이터의 개수: {}'.format(len(dev_labels)))\r\n",
        "print('전체 프랜즈 dev마스크 데이터의 개수: {}'.format(len(dev_masks)))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 프랜즈 dev학  습 데이터의 개수: 1178\n",
            "전체 프랜즈 dev라  벨 데이터의 개수: 1178\n",
            "전체 프랜즈 dev마스크 데이터의 개수: 1178\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCA3Y21JaYVG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5fa978c-4552-453e-b779-4eb716ffc016"
      },
      "source": [
        "print('전체 프랜즈 test학  습 데이터의 개수: {}'.format(len(test_inputs)))\r\n",
        "print('전체 프랜즈 test라  벨 데이터의 개수: {}'.format(len(test_labels)))\r\n",
        "print('전체 프랜즈 test마스크 데이터의 개수: {}'.format(len(test_masks)))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 프랜즈 test학  습 데이터의 개수: 2764\n",
            "전체 프랜즈 test라  벨 데이터의 개수: 2764\n",
            "전체 프랜즈 test마스크 데이터의 개수: 2764\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHvhA-fDaYXf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebaa8fa8-acc4-41ca-b098-16e70065d16a"
      },
      "source": [
        "print('전체 프랜즈 test1 학  습 데이터의 개수: {}'.format(len(test_df_inputs)))\r\n",
        "print('전체 프랜즈 test1 마스크 데이터의 개수: {}'.format(len(test_df_masks)))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 프랜즈 test1 학  습 데이터의 개수: 1623\n",
            "전체 프랜즈 test1 마스크 데이터의 개수: 1623\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQO1Uw037oXN"
      },
      "source": [
        "## 1.2 IMDB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "6RUiPvka7n3z",
        "outputId": "aa8dce5c-715b-4f79-b5d8-93651a63b757"
      },
      "source": [
        "#IMDB data\r\n",
        "train_data_db = pd.read_csv('EN_Sentiment-Analysis/data_in/labeledTrainData.tsv', header = 0, delimiter = '\\t', quoting = 3)\r\n",
        "train_data_db.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"5814_8\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"With all this stuff going down at the moment ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"2381_9\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"7759_3\"</td>\n",
              "      <td>0</td>\n",
              "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"3630_4\"</td>\n",
              "      <td>0</td>\n",
              "      <td>\"It must be assumed that those who praised thi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"9495_8\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"Superbly trashy and wondrously unpretentious ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  sentiment                                             review\n",
              "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
              "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
              "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...\n",
              "3  \"3630_4\"          0  \"It must be assumed that those who praised thi...\n",
              "4  \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "XznYAWQL7vO7",
        "outputId": "015b5442-4b82-4a95-fc40-e7cea926fbc3"
      },
      "source": [
        "# 감정을 숫자로 변환\r\n",
        "def emotion_labeling_mv(emotion):\r\n",
        "   return{0 : 'anger',1:'joy'}[emotion]\r\n",
        "\r\n",
        "emotion_labels = []\r\n",
        "\r\n",
        "for e in train_data_db['sentiment']:\r\n",
        "   emotion_labels.append(emotion_labeling_mv(e))\r\n",
        "\r\n",
        "train_data_db['label'] = emotion_labels\r\n",
        "train_data_db[:10]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"5814_8\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"With all this stuff going down at the moment ...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"2381_9\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"7759_3\"</td>\n",
              "      <td>0</td>\n",
              "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"3630_4\"</td>\n",
              "      <td>0</td>\n",
              "      <td>\"It must be assumed that those who praised thi...</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"9495_8\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"Superbly trashy and wondrously unpretentious ...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>\"8196_8\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"I dont know why people think this is such a b...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>\"7166_2\"</td>\n",
              "      <td>0</td>\n",
              "      <td>\"This movie could have been very good, but com...</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>\"10633_1\"</td>\n",
              "      <td>0</td>\n",
              "      <td>\"I watched this video at a friend's house. I'm...</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>\"319_1\"</td>\n",
              "      <td>0</td>\n",
              "      <td>\"A friend of mine bought this film for £1, and...</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>\"8713_10\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"&lt;br /&gt;&lt;br /&gt;This movie is full of references....</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  ...  label\n",
              "0   \"5814_8\"  ...    joy\n",
              "1   \"2381_9\"  ...    joy\n",
              "2   \"7759_3\"  ...  anger\n",
              "3   \"3630_4\"  ...  anger\n",
              "4   \"9495_8\"  ...    joy\n",
              "5   \"8196_8\"  ...    joy\n",
              "6   \"7166_2\"  ...  anger\n",
              "7  \"10633_1\"  ...  anger\n",
              "8    \"319_1\"  ...  anger\n",
              "9  \"8713_10\"  ...    joy\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmtaDYuy7vMD"
      },
      "source": [
        "def cleaning_mv(str):\r\n",
        "    replaceAll= str\r\n",
        "    only_english = re.sub('<br />', '', replaceAll)\r\n",
        "    return only_english\r\n",
        "\r\n",
        "def getInputsAndLabels2(dataset):\r\n",
        "  data = dataset.copy(deep=True)\r\n",
        "\r\n",
        "  utterances = data['review']\r\n",
        "  utterances = [\"[CLS] \" + str(cleaning_mv(utterance)) + \" [SEP]\" for utterance in utterances]\r\n",
        "  \r\n",
        "  encoder = LabelEncoder()\r\n",
        "  labels = data['label'].values\r\n",
        "  encoder.fit(labels)\r\n",
        "  labels = encoder.transform(labels)\r\n",
        "\r\n",
        "  tokenizer = BertTokenizer.from_pretrained(TOKEN_MODEL, do_lower_case=False)\r\n",
        "  tokenized_texts = [tokenizer.tokenize(utterance) for utterance in utterances]\r\n",
        "\r\n",
        "  input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\r\n",
        "  input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\r\n",
        "\r\n",
        "  attention_masks = []\r\n",
        "  for seq in input_ids:\r\n",
        "      seq_mask = [float(i>0) for i in seq]\r\n",
        "      attention_masks.append(seq_mask)\r\n",
        "\r\n",
        "  return input_ids, labels, attention_masks\r\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-1PwTJL7vRS"
      },
      "source": [
        "train_inputs2, train_labels2, train_masks2 = getInputsAndLabels2(train_data_db)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5k0ODIde7vTT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f83513ed-08b9-4ad1-c607-f2bd076aca68"
      },
      "source": [
        "print('전체 IMDB 학  습 데이터의 개수: {}'.format(len(train_inputs2)))\r\n",
        "print('전체 IMDB 라  벨 데이터의 개수: {}'.format(len(train_labels2)))\r\n",
        "print('전체 IMDB 마스크 데이터의 개수: {}'.format(len(train_masks2)))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 IMDB 학  습 데이터의 개수: 25000\n",
            "전체 IMDB 라  벨 데이터의 개수: 25000\n",
            "전체 IMDB 마스크 데이터의 개수: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ybz5PtDcW8P"
      },
      "source": [
        "train_masks0 = []\r\n",
        "train_masks0.extend(train_masks1)\r\n",
        "train_masks0.extend(train_masks2)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiRnsncnU6HV"
      },
      "source": [
        "train_labels0 = []\r\n",
        "train_labels0.extend(train_labels1)\r\n",
        "train_labels0.extend(train_labels2)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xb7JaB6bU6Kz"
      },
      "source": [
        "train_inputs0 = []\r\n",
        "train_inputs0.extend(train_inputs1)\r\n",
        "train_inputs0.extend(train_inputs2)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m15u04rcW6A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69738fe5-abfa-48ea-fa99-fecbb60e1cb8"
      },
      "source": [
        "print('전체 학  습 데이터의 개수: {}'.format(len(train_inputs0)))\r\n",
        "print('전체 라  벨 데이터의 개수: {}'.format(len(train_labels0)))\r\n",
        "print('전체 마스크 데이터의 개수: {}'.format(len(train_masks0)))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 학  습 데이터의 개수: 35561\n",
            "전체 라  벨 데이터의 개수: 35561\n",
            "전체 마스크 데이터의 개수: 35561\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_xnZrX_cW1s"
      },
      "source": [
        "train_inputs = torch.tensor(train_inputs0)\r\n",
        "train_labels = torch.tensor(train_labels0)\r\n",
        "train_masks = torch.tensor(train_masks0)\r\n",
        "\r\n",
        "dev_inputs = torch.tensor(dev_inputs)\r\n",
        "dev_labels = torch.tensor(dev_labels)\r\n",
        "dev_masks = torch.tensor(dev_masks)\r\n",
        "\r\n",
        "test_inputs = torch.tensor(test_inputs)\r\n",
        "test_labels = torch.tensor(test_labels)\r\n",
        "test_masks = torch.tensor(test_masks)\r\n",
        "\r\n",
        "test_df_index = getIndex(test_df)\r\n",
        "test_df_inputs = torch.tensor(test_df_inputs)\r\n",
        "test_df_masks = torch.tensor(test_df_masks)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZOboXJmcWza"
      },
      "source": [
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\r\n",
        "train_sampler = RandomSampler(train_data)\r\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\r\n",
        "\r\n",
        "dev_data = TensorDataset(dev_inputs, dev_masks, dev_labels)\r\n",
        "dev_sampler = SequentialSampler(dev_data)\r\n",
        "dev_dataloader = DataLoader(dev_data, sampler=dev_sampler, batch_size=batch_size)\r\n",
        "\r\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\r\n",
        "test_sampler = RandomSampler(test_data)\r\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\r\n",
        "\r\n",
        "test_df_data = TensorDataset(test_df_index, test_df_inputs, test_df_masks)\r\n",
        "test_df_sampler = RandomSampler(test_df_data)\r\n",
        "test_df_dataloader = DataLoader(test_df_data, sampler=test_df_sampler, batch_size=batch_size)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afbtrT3hg6sr"
      },
      "source": [
        "# 2. 모델 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rm8tkXDEg0h9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e9fd6d3-f7f7-47f2-d28a-ef91b03944c9"
      },
      "source": [
        "# 디바이스 설정\r\n",
        "if torch.cuda.is_available():    \r\n",
        "    device = torch.device(\"cuda\")\r\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\r\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\r\n",
        "else:\r\n",
        "    device = torch.device(\"cpu\")\r\n",
        "    print('No GPU available, using the CPU instead.')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla V100-SXM2-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s40-YjZPKyft",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "13ed923a528641178b4bb701471f99c7",
            "c61061d0178d43ee98a81b12fffd941c",
            "ed4b84f8558545adbd1326dfbde89d26",
            "e5ac9ec689ae45aab273f47b01ac31c1",
            "638f78e48a3442edb832795a947ea99a",
            "77b49e6ba1cb49478c6a5513c92951bd",
            "451592c5c0d645bead359ce5eb8e2456",
            "818eb7bc16cf4807a16983e81a19e7b1",
            "5590e94f2b97466e9aa1fe3251a4c627",
            "5cdab5c414ae43889dbe4f3f47df45f1",
            "a73624af91dd471a8cb4adf315e95cfe",
            "1e4dd05f70e74cef9fb051048dba4a6a",
            "ff8b4b74424e4cc6bb8ac29f491c8e29",
            "5a1565762b1349c19d2087cf9067a139",
            "e35a419193a44a03a11cd601ee3e5e6d",
            "ccbbeedaf78b4312a8d61a51c3369858"
          ]
        },
        "outputId": "5e8df3e7-9dcd-44ea-a6ae-ad020f47ada2"
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(TRAIN_MODEL, num_labels=8)\n",
        "model.cuda()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "13ed923a528641178b4bb701471f99c7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5590e94f2b97466e9aa1fe3251a4c627",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=8, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZwXlNqahGVe"
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\r\n",
        "                  lr = 2e-5, \r\n",
        "                  eps = 1e-8\r\n",
        "                )\r\n",
        "\r\n",
        "total_steps = len(train_dataloader) * epochs\r\n",
        "\r\n",
        "# 학습률을 조금씩 감소시키는 스케줄러 생성\r\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \r\n",
        "                                            num_warmup_steps = 0,\r\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9fpiLtphLEr"
      },
      "source": [
        "#학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSgXgK1thGYR"
      },
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\r\n",
        "from sklearn.metrics import confusion_matrix, classification_report\r\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\r\n",
        "import seaborn as sns\r\n",
        "\r\n",
        "# 정확도 계산 함수\r\n",
        "def flat_accuracy(preds, labels):\r\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\r\n",
        "    labels_flat = labels.flatten()\r\n",
        "\r\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\r\n",
        "\r\n",
        "# 시간 표시 함수\r\n",
        "def format_time(elapsed):\r\n",
        "\r\n",
        "    # 반올림\r\n",
        "    elapsed_rounded = int(round((elapsed)))\r\n",
        "    \r\n",
        "    # hh:mm:ss으로 형태 변경\r\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\r\n",
        "\r\n",
        "#평가함수\r\n",
        "def evaluate(true_list, pred_list):\r\n",
        "\r\n",
        "  accuracy = accuracy_score(true_list, pred_list)\r\n",
        "  precision = precision_score(true_list, pred_list, average=None)\r\n",
        "  recall = recall_score(true_list, pred_list, average=None)\r\n",
        "  micro_f1 = f1_score(true_list, pred_list, average='micro')\r\n",
        "\r\n",
        "  print(\"accuracy:{0:.4f}\".format(accuracy))\r\n",
        "  print('precision:\\t', ['%.4f' % v for v in precision])\r\n",
        "  print('recall:\\t\\t', ['%.4f' % v for v in recall])\r\n",
        "  print('micro_f1: %.6f' % micro_f1)\r\n",
        "\r\n",
        "  n_correct = [x for x, y in zip(true_list, pred_list) if x == y]\r\n",
        "  cnt_list = [0] * (8)\r\n",
        "  for cnt in n_correct:\r\n",
        "    if cnt==0:\r\n",
        "      cnt_list[cnt]+=1\r\n",
        "    elif cnt==1:\r\n",
        "      cnt_list[cnt]+=1\r\n",
        "    elif cnt==2:\r\n",
        "      cnt_list[cnt]+=1\r\n",
        "    elif cnt==3:\r\n",
        "      cnt_list[cnt]+=1\r\n",
        "    elif cnt==4:\r\n",
        "      cnt_list[cnt]+=1\r\n",
        "    elif cnt==5:\r\n",
        "      cnt_list[cnt]+=1\r\n",
        "    elif cnt==6:\r\n",
        "      cnt_list[cnt]+=1\r\n",
        "    elif cnt==7:\r\n",
        "      cnt_list[cnt]+=1\r\n",
        "\r\n",
        "  print(\"각 라벨 별 정답 cnt_list\",cnt_list)\r\n",
        "  return cnt_list\r\n",
        "\r\n",
        "def matrix_evaluate(true_list, pred_list, cnt_list):\r\n",
        "  target_names = ['anger', 'disgust', 'fear', 'joy', 'neutral', 'non-neutral', 'sadness', 'surprise'] \r\n",
        "\r\n",
        "  cm = confusion_matrix(true_list, pred_list)\r\n",
        "  sns.heatmap(cm, annot = True, fmt = 'd',cmap = 'Blues',) \r\n",
        "  print(classification_report(true_list, pred_list, digits=4, target_names=target_names))\r\n",
        " "
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYaXtdwbhGa2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dffa1833-9164-432e-f103-ea04a3c1d75b"
      },
      "source": [
        "seed_val = 42\r\n",
        "random.seed(seed_val)\r\n",
        "np.random.seed(seed_val)\r\n",
        "torch.manual_seed(seed_val)\r\n",
        "torch.cuda.manual_seed_all(seed_val)\r\n",
        "\r\n",
        "model.zero_grad()\r\n",
        "\r\n",
        "for epoch_i in range(0, epochs):\r\n",
        "    \r\n",
        "    # ========================================\r\n",
        "    #               Training\r\n",
        "    # ========================================\r\n",
        "    print(\"\")\r\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\r\n",
        "    print('Training...')\r\n",
        "\r\n",
        "    t0 = time.time()\r\n",
        "    total_loss = 0\r\n",
        "    model.train()\r\n",
        "        \r\n",
        "    # 데이터로더에서 배치만큼 반복하여 가져옴\r\n",
        "    for step, batch in enumerate(train_dataloader):\r\n",
        "        if step % 500 == 0 and not step == 0:\r\n",
        "            elapsed = format_time(time.time() - t0)\r\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\r\n",
        "\r\n",
        "        batch = tuple(t.to(device) for t in batch)\r\n",
        "        b_input_ids, b_input_mask, b_labels = batch\r\n",
        "             \r\n",
        "        outputs = model(b_input_ids, \r\n",
        "                        token_type_ids=None, \r\n",
        "                        attention_mask=b_input_mask, \r\n",
        "                        labels=b_labels)\r\n",
        "\r\n",
        "        loss = outputs[0]\r\n",
        "        total_loss += loss.item()\r\n",
        "\r\n",
        "        loss.backward()\r\n",
        "\r\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\r\n",
        "        optimizer.step()\r\n",
        "        scheduler.step()\r\n",
        "        model.zero_grad()\r\n",
        "\r\n",
        "    # 평균 로스 계산\r\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \r\n",
        "\r\n",
        "    print(\"\")\r\n",
        "    print(\"  Average training loss: {0:.5f}\".format(avg_train_loss))\r\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\r\n",
        "        \r\n",
        "    # ========================================\r\n",
        "    #               Validation\r\n",
        "    # ========================================\r\n",
        "    print(\"\")\r\n",
        "    print(\"Running Validation...\")\r\n",
        "\r\n",
        "    t0 = time.time()\r\n",
        "    model.eval()\r\n",
        "\r\n",
        "    eval_accuracy, nb_eval_steps = 0, 0\r\n",
        "    pred_list, true_list = [], []\r\n",
        "\r\n",
        "    for batch in dev_dataloader:\r\n",
        "        batch = tuple(t.to(device) for t in batch)\r\n",
        "        b_input_ids, b_input_mask, b_labels = batch\r\n",
        "\r\n",
        "        with torch.no_grad():     \r\n",
        "            outputs = model(b_input_ids, \r\n",
        "                            token_type_ids=None, \r\n",
        "                            attention_mask=b_input_mask)\r\n",
        "        \r\n",
        "        logits = outputs[0]\r\n",
        "        logits = logits.detach().cpu().numpy()\r\n",
        "        label_ids = b_labels.to('cpu').numpy()\r\n",
        "     \r\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\r\n",
        "        eval_accuracy += tmp_eval_accuracy\r\n",
        "        nb_eval_steps += 1\r\n",
        "\r\n",
        "        pred_flat = np.argmax(logits, axis=1).flatten()\r\n",
        "        trues_flat = label_ids.flatten()\r\n",
        "        pred_list.extend(pred_flat)\r\n",
        "        true_list.extend(trues_flat)\r\n",
        "\r\n",
        "    print(\"  Accuracy: {0:.5f}\".format(eval_accuracy/nb_eval_steps))\r\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\r\n",
        "    cnt_list = evaluate(pred_list, true_list) # print results\r\n",
        "\r\n",
        "print(\"\")\r\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 20 ========\n",
            "Training...\n",
            "  Batch   500  of  1,112.    Elapsed: 0:01:31.\n",
            "  Batch 1,000  of  1,112.    Elapsed: 0:03:02.\n",
            "\n",
            "  Average training loss: 0.71785\n",
            "  Training epcoh took: 0:03:22\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.52280\n",
            "  Validation took: 0:00:02\n",
            "accuracy:0.5229\n",
            "precision:\t ['0.3059', '0.0000', '0.0000', '0.6016', '0.8371', '0.1776', '0.3710', '0.2914']\n",
            "recall:\t\t ['0.3939', '0.0000', '0.0000', '0.5000', '0.6565', '0.2249', '0.2987', '0.4783']\n",
            "micro_f1: 0.522920\n",
            "각 라벨 별 정답 cnt_list [26, 0, 0, 74, 411, 38, 23, 44]\n",
            "\n",
            "======== Epoch 2 / 20 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch   500  of  1,112.    Elapsed: 0:01:30.\n",
            "  Batch 1,000  of  1,112.    Elapsed: 0:03:01.\n",
            "\n",
            "  Average training loss: 0.52846\n",
            "  Training epcoh took: 0:03:21\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.54944\n",
            "  Validation took: 0:00:02\n",
            "accuracy:0.5501\n",
            "precision:\t ['0.1765', '0.0000', '0.0000', '0.6667', '0.8717', '0.2290', '0.3387', '0.3510']\n",
            "recall:\t\t ['0.4839', '0.0000', '0.0000', '0.4409', '0.6751', '0.2649', '0.4773', '0.5408']\n",
            "micro_f1: 0.550085\n",
            "각 라벨 별 정답 cnt_list [15, 0, 0, 82, 428, 49, 21, 53]\n",
            "\n",
            "======== Epoch 3 / 20 ========\n",
            "Training...\n",
            "  Batch   500  of  1,112.    Elapsed: 0:01:30.\n",
            "  Batch 1,000  of  1,112.    Elapsed: 0:03:01.\n",
            "\n",
            "  Average training loss: 0.40776\n",
            "  Training epcoh took: 0:03:21\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.55152\n",
            "  Validation took: 0:00:02\n",
            "accuracy:0.5518\n",
            "precision:\t ['0.1647', '0.0435', '0.0345', '0.4553', '0.8574', '0.2430', '0.3226', '0.5629']\n",
            "recall:\t\t ['0.5185', '0.5000', '0.2500', '0.5490', '0.6768', '0.2873', '0.4255', '0.4404']\n",
            "micro_f1: 0.551783\n",
            "각 라벨 별 정답 cnt_list [14, 1, 1, 56, 421, 52, 20, 85]\n",
            "\n",
            "======== Epoch 4 / 20 ========\n",
            "Training...\n",
            "  Batch   500  of  1,112.    Elapsed: 0:01:30.\n",
            "  Batch 1,000  of  1,112.    Elapsed: 0:03:00.\n",
            "\n",
            "  Average training loss: 0.30500\n",
            "  Training epcoh took: 0:03:20\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.53528\n",
            "  Validation took: 0:00:02\n",
            "accuracy:0.5357\n",
            "precision:\t ['0.2471', '0.0435', '0.0690', '0.6423', '0.7637', '0.3131', '0.3065', '0.4437']\n",
            "recall:\t\t ['0.5385', '0.5000', '1.0000', '0.4341', '0.6996', '0.2669', '0.4318', '0.5492']\n",
            "micro_f1: 0.535654\n",
            "각 라벨 별 정답 cnt_list [21, 1, 2, 79, 375, 67, 19, 67]\n",
            "\n",
            "======== Epoch 5 / 20 ========\n",
            "Training...\n",
            "  Batch   500  of  1,112.    Elapsed: 0:01:30.\n",
            "  Batch 1,000  of  1,112.    Elapsed: 0:03:00.\n",
            "\n",
            "  Average training loss: 0.23455\n",
            "  Training epcoh took: 0:03:21\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.50552\n",
            "  Validation took: 0:00:02\n",
            "accuracy:0.5059\n",
            "precision:\t ['0.2235', '0.0435', '0.0345', '0.6260', '0.6680', '0.3505', '0.2419', '0.5298']\n",
            "recall:\t\t ['0.6552', '0.2500', '0.2500', '0.3949', '0.7115', '0.2852', '0.6250', '0.4040']\n",
            "micro_f1: 0.505942\n",
            "각 라벨 별 정답 cnt_list [19, 1, 1, 77, 328, 75, 15, 80]\n",
            "\n",
            "======== Epoch 6 / 20 ========\n",
            "Training...\n",
            "  Batch   500  of  1,112.    Elapsed: 0:01:30.\n",
            "  Batch 1,000  of  1,112.    Elapsed: 0:03:00.\n",
            "\n",
            "  Average training loss: 0.18261\n",
            "  Training epcoh took: 0:03:21\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.52807\n",
            "  Validation took: 0:00:02\n",
            "accuracy:0.5280\n",
            "precision:\t ['0.3176', '0.1304', '0.0690', '0.6341', '0.7454', '0.2757', '0.2097', '0.4901']\n",
            "recall:\t\t ['0.4655', '0.3333', '0.2222', '0.3980', '0.6816', '0.3352', '0.5000', '0.4431']\n",
            "micro_f1: 0.528014\n",
            "각 라벨 별 정답 cnt_list [27, 3, 2, 78, 366, 59, 13, 74]\n",
            "\n",
            "======== Epoch 7 / 20 ========\n",
            "Training...\n",
            "  Batch   500  of  1,112.    Elapsed: 0:01:30.\n",
            "  Batch 1,000  of  1,112.    Elapsed: 0:03:01.\n",
            "\n",
            "  Average training loss: 0.14830\n",
            "  Training epcoh took: 0:03:21\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.52956\n",
            "  Validation took: 0:00:02\n",
            "accuracy:0.5297\n",
            "precision:\t ['0.2353', '0.0870', '0.0690', '0.5122', '0.7821', '0.4019', '0.2258', '0.3510']\n",
            "recall:\t\t ['0.5556', '0.3333', '0.4000', '0.4437', '0.6737', '0.2966', '0.5385', '0.5146']\n",
            "micro_f1: 0.529711\n",
            "각 라벨 별 정답 cnt_list [20, 2, 2, 63, 384, 86, 14, 53]\n",
            "\n",
            "======== Epoch 8 / 20 ========\n",
            "Training...\n",
            "  Batch   500  of  1,112.    Elapsed: 0:01:30.\n",
            "  Batch 1,000  of  1,112.    Elapsed: 0:03:00.\n",
            "\n",
            "  Average training loss: 0.12154\n",
            "  Training epcoh took: 0:03:20\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.51293\n",
            "  Validation took: 0:00:02\n",
            "accuracy:0.5136\n",
            "precision:\t ['0.2000', '0.0870', '0.1034', '0.4959', '0.7515', '0.2944', '0.2581', '0.4901']\n",
            "recall:\t\t ['0.4857', '0.2222', '0.1364', '0.4552', '0.6783', '0.2681', '0.4103', '0.4625']\n",
            "micro_f1: 0.513582\n",
            "각 라벨 별 정답 cnt_list [17, 2, 3, 61, 369, 63, 16, 74]\n",
            "\n",
            "======== Epoch 9 / 20 ========\n",
            "Training...\n",
            "  Batch   500  of  1,112.    Elapsed: 0:01:30.\n",
            "  Batch 1,000  of  1,112.    Elapsed: 0:03:00.\n",
            "\n",
            "  Average training loss: 0.10749\n",
            "  Training epcoh took: 0:03:20\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.51897\n",
            "  Validation took: 0:00:02\n",
            "accuracy:0.5187\n",
            "precision:\t ['0.2824', '0.1739', '0.1034', '0.5772', '0.7373', '0.3598', '0.2903', '0.3444']\n",
            "recall:\t\t ['0.5333', '0.3077', '0.1579', '0.3966', '0.6962', '0.2841', '0.5455', '0.5306']\n",
            "micro_f1: 0.518676\n",
            "각 라벨 별 정답 cnt_list [24, 4, 3, 71, 362, 77, 18, 52]\n",
            "\n",
            "======== Epoch 10 / 20 ========\n",
            "Training...\n",
            "  Batch   500  of  1,112.    Elapsed: 0:01:29.\n",
            "  Batch 1,000  of  1,112.    Elapsed: 0:03:00.\n",
            "\n",
            "  Average training loss: 0.09343\n",
            "  Training epcoh took: 0:03:20\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.53041\n",
            "  Validation took: 0:00:02\n",
            "accuracy:0.5306\n",
            "precision:\t ['0.2118', '0.1304', '0.1379', '0.5935', '0.7780', '0.3364', '0.2258', '0.3907']\n",
            "recall:\t\t ['0.4737', '0.5000', '0.2222', '0.4124', '0.6984', '0.3158', '0.4375', '0.4470']\n",
            "micro_f1: 0.530560\n",
            "각 라벨 별 정답 cnt_list [18, 3, 4, 73, 382, 72, 14, 59]\n",
            "\n",
            "======== Epoch 11 / 20 ========\n",
            "Training...\n",
            "  Batch   500  of  1,112.    Elapsed: 0:01:30.\n",
            "  Batch 1,000  of  1,112.    Elapsed: 0:02:59.\n",
            "\n",
            "  Average training loss: 0.08347\n",
            "  Training epcoh took: 0:03:19\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.51904\n",
            "  Validation took: 0:00:02\n",
            "accuracy:0.5195\n",
            "precision:\t ['0.1882', '0.1739', '0.1034', '0.5366', '0.7413', '0.3692', '0.2258', '0.4371']\n",
            "recall:\t\t ['0.5333', '0.3077', '0.3000', '0.4459', '0.7000', '0.2811', '0.5000', '0.4459']\n",
            "micro_f1: 0.519525\n",
            "각 라벨 별 정답 cnt_list [16, 4, 3, 66, 364, 79, 14, 66]\n",
            "\n",
            "======== Epoch 12 / 20 ========\n",
            "Training...\n",
            "  Batch   500  of  1,112.    Elapsed: 0:01:30.\n",
            "  Batch 1,000  of  1,112.    Elapsed: 0:03:00.\n",
            "\n",
            "  Average training loss: 0.07867\n",
            "  Training epcoh took: 0:03:20\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.52833\n",
            "  Validation took: 0:00:02\n",
            "accuracy:0.5289\n",
            "precision:\t ['0.2000', '0.1739', '0.1034', '0.6179', '0.7475', '0.3458', '0.2097', '0.4570']\n",
            "recall:\t\t ['0.5484', '0.3077', '0.2727', '0.4318', '0.6938', '0.3122', '0.5200', '0.4423']\n",
            "micro_f1: 0.528862\n",
            "각 라벨 별 정답 cnt_list [17, 4, 3, 76, 367, 74, 13, 69]\n",
            "\n",
            "======== Epoch 13 / 20 ========\n",
            "Training...\n",
            "  Batch   500  of  1,112.    Elapsed: 0:01:29.\n",
            "  Batch 1,000  of  1,112.    Elapsed: 0:02:59.\n",
            "\n",
            "  Average training loss: 0.07182\n",
            "  Training epcoh took: 0:03:19\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.53190\n",
            "  Validation took: 0:00:02\n",
            "accuracy:0.5323\n",
            "precision:\t ['0.2118', '0.1739', '0.1379', '0.5854', '0.7536', '0.3692', '0.2097', '0.4437']\n",
            "recall:\t\t ['0.5625', '0.3636', '0.3636', '0.4211', '0.6916', '0.3185', '0.5000', '0.4653']\n",
            "micro_f1: 0.532258\n",
            "각 라벨 별 정답 cnt_list [18, 4, 4, 72, 370, 79, 13, 67]\n",
            "\n",
            "======== Epoch 14 / 20 ========\n",
            "Training...\n",
            "  Batch   500  of  1,112.    Elapsed: 0:01:29.\n",
            "  Batch 1,000  of  1,112.    Elapsed: 0:02:58.\n",
            "\n",
            "  Average training loss: 0.06711\n",
            "  Training epcoh took: 0:03:18\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.53041\n",
            "  Validation took: 0:00:02\n",
            "accuracy:0.5306\n",
            "precision:\t ['0.1765', '0.1739', '0.1379', '0.4228', '0.7800', '0.3738', '0.2581', '0.4702']\n",
            "recall:\t\t ['0.5556', '0.3333', '0.2000', '0.4727', '0.7002', '0.3137', '0.4706', '0.4104']\n",
            "micro_f1: 0.530560\n",
            "각 라벨 별 정답 cnt_list [15, 4, 4, 52, 383, 80, 16, 71]\n",
            "\n",
            "======== Epoch 15 / 20 ========\n",
            "Training...\n",
            "  Batch   500  of  1,112.    Elapsed: 0:01:29.\n",
            "  Batch 1,000  of  1,112.    Elapsed: 0:02:58.\n",
            "\n",
            "  Average training loss: 0.06590\n",
            "  Training epcoh took: 0:03:18\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.52872\n",
            "  Validation took: 0:00:02\n",
            "accuracy:0.5289\n",
            "precision:\t ['0.2353', '0.1739', '0.1724', '0.5772', '0.7637', '0.3692', '0.2258', '0.3642']\n",
            "recall:\t\t ['0.5128', '0.3636', '0.3125', '0.4437', '0.6970', '0.2842', '0.5600', '0.4955']\n",
            "micro_f1: 0.528862\n",
            "각 라벨 별 정답 cnt_list [20, 4, 5, 71, 375, 79, 14, 55]\n",
            "\n",
            "======== Epoch 16 / 20 ========\n",
            "Training...\n",
            "  Batch   500  of  1,112.    Elapsed: 0:01:29.\n",
            "  Batch 1,000  of  1,112.    Elapsed: 0:02:58.\n",
            "\n",
            "  Average training loss: 0.06206\n",
            "  Training epcoh took: 0:03:18\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.52449\n",
            "  Validation took: 0:00:02\n",
            "accuracy:0.5246\n",
            "precision:\t ['0.2471', '0.2174', '0.2069', '0.6341', '0.7413', '0.3505', '0.2419', '0.3576']\n",
            "recall:\t\t ['0.4565', '0.3846', '0.2308', '0.4127', '0.7137', '0.2953', '0.5172', '0.4865']\n",
            "micro_f1: 0.524618\n",
            "각 라벨 별 정답 cnt_list [21, 5, 6, 78, 364, 75, 15, 54]\n",
            "\n",
            "======== Epoch 17 / 20 ========\n",
            "Training...\n",
            "  Batch   500  of  1,112.    Elapsed: 0:01:29.\n",
            "  Batch 1,000  of  1,112.    Elapsed: 0:02:58.\n",
            "\n",
            "  Average training loss: 0.05908\n",
            "  Training epcoh took: 0:03:18\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.53651\n",
            "  Validation took: 0:00:02\n",
            "accuracy:0.5365\n",
            "precision:\t ['0.2235', '0.1739', '0.2414', '0.5610', '0.7882', '0.3318', '0.2097', '0.4106']\n",
            "recall:\t\t ['0.5000', '0.4000', '0.3684', '0.4157', '0.6898', '0.3114', '0.5417', '0.4697']\n",
            "micro_f1: 0.536503\n",
            "각 라벨 별 정답 cnt_list [19, 4, 7, 69, 387, 71, 13, 62]\n",
            "\n",
            "======== Epoch 18 / 20 ========\n",
            "Training...\n",
            "  Batch   500  of  1,112.    Elapsed: 0:01:28.\n",
            "  Batch 1,000  of  1,112.    Elapsed: 0:02:57.\n",
            "\n",
            "  Average training loss: 0.05673\n",
            "  Training epcoh took: 0:03:17\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.52976\n",
            "  Validation took: 0:00:02\n",
            "accuracy:0.5297\n",
            "precision:\t ['0.1882', '0.2174', '0.1724', '0.6016', '0.7739', '0.3551', '0.2258', '0.3576']\n",
            "recall:\t\t ['0.5333', '0.4545', '0.2941', '0.4066', '0.7011', '0.2912', '0.5185', '0.5000']\n",
            "micro_f1: 0.529711\n",
            "각 라벨 별 정답 cnt_list [16, 5, 5, 74, 380, 76, 14, 54]\n",
            "\n",
            "======== Epoch 19 / 20 ========\n",
            "Training...\n",
            "  Batch   500  of  1,112.    Elapsed: 0:01:28.\n",
            "  Batch 1,000  of  1,112.    Elapsed: 0:02:57.\n",
            "\n",
            "  Average training loss: 0.05536\n",
            "  Training epcoh took: 0:03:17\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.53612\n",
            "  Validation took: 0:00:02\n",
            "accuracy:0.5365\n",
            "precision:\t ['0.2000', '0.2174', '0.1379', '0.5772', '0.7882', '0.3738', '0.2258', '0.3576']\n",
            "recall:\t\t ['0.5312', '0.4545', '0.2667', '0.4437', '0.7036', '0.2930', '0.5385', '0.4865']\n",
            "micro_f1: 0.536503\n",
            "각 라벨 별 정답 cnt_list [17, 5, 4, 71, 387, 80, 14, 54]\n",
            "\n",
            "======== Epoch 20 / 20 ========\n",
            "Training...\n",
            "  Batch   500  of  1,112.    Elapsed: 0:01:28.\n",
            "  Batch 1,000  of  1,112.    Elapsed: 0:02:57.\n",
            "\n",
            "  Average training loss: 0.05321\n",
            "  Training epcoh took: 0:03:16\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.52937\n",
            "  Validation took: 0:00:02\n",
            "accuracy:0.5297\n",
            "precision:\t ['0.2000', '0.2174', '0.1034', '0.5772', '0.7800', '0.3551', '0.2258', '0.3642']\n",
            "recall:\t\t ['0.4722', '0.4167', '0.2143', '0.4329', '0.7028', '0.2857', '0.5385', '0.4783']\n",
            "micro_f1: 0.529711\n",
            "각 라벨 별 정답 cnt_list [17, 5, 3, 71, 383, 76, 14, 55]\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JKfoqdTbni0"
      },
      "source": [
        "# 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KB_Nvm-16ohw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5cad533-4724-4914-d4f1-de619594b695"
      },
      "source": [
        "#시작 시간 설정\r\n",
        "t0 = time.time()\r\n",
        "\r\n",
        "# 평가모드로 변경\r\n",
        "model.eval()\r\n",
        "\r\n",
        "# 변수 초기화\r\n",
        "f1_score_avg = []\r\n",
        "pred_list, true_list = [], []\r\n",
        "eval_loss, eval_accuracy = 0, 0\r\n",
        "nb_eval_steps, nb_eval_examples = 0, 0\r\n",
        "\r\n",
        "for step, batch in enumerate(test_dataloader):\r\n",
        "    if step % 100 == 0 and not step == 0:\r\n",
        "        elapsed = format_time(time.time() - t0)\r\n",
        "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\r\n",
        "\r\n",
        "    batch = tuple(t.to(device) for t in batch)\r\n",
        "    b_input_ids, b_input_mask, b_labels = batch\r\n",
        "    \r\n",
        "    # 그래디언트 계산 안함\r\n",
        "    with torch.no_grad():     \r\n",
        "        # Forward 수행\r\n",
        "        outputs = model(b_input_ids, \r\n",
        "                        token_type_ids=None, \r\n",
        "                        attention_mask=b_input_mask)\r\n",
        "    \r\n",
        "    logits = outputs[0]\r\n",
        "\r\n",
        "    # CPU로 데이터 이동\r\n",
        "    logits = logits.detach().cpu().numpy()\r\n",
        "    label_ids = b_labels.to('cpu').numpy()\r\n",
        "\r\n",
        "    pred_flat = np.argmax(logits, axis=1).flatten()\r\n",
        "    trues_flat = label_ids.flatten()\r\n",
        "    pred_list.extend(pred_flat)\r\n",
        "    true_list.extend(trues_flat)\r\n",
        "    \r\n",
        "    # 출력 로짓과 라벨을 비교하여 정확도 계산\r\n",
        "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\r\n",
        "    eval_accuracy += tmp_eval_accuracy\r\n",
        "    nb_eval_steps += 1\r\n",
        "\r\n",
        "print(\"\")\r\n",
        "print(\"  Accuracy: {0:.5f}\".format(eval_accuracy/nb_eval_steps))\r\n",
        "print(\"Test took: {:}\".format(format_time(time.time() - t0)))\r\n",
        "print(\"Emotion accuracy\")\r\n",
        "cnt_list = evaluate(pred_list, true_list) # print results\r\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  Accuracy: 0.55460\n",
            "Test took: 0:00:04\n",
            "Emotion accuracy\n",
            "accuracy:0.5550\n",
            "precision:\t ['0.2547', '0.0882', '0.1250', '0.5987', '0.7653', '0.3105', '0.2706', '0.4371']\n",
            "recall:\t\t ['0.4881', '0.1250', '0.1212', '0.4727', '0.7253', '0.3105', '0.3710', '0.4941']\n",
            "micro_f1: 0.554993\n",
            "각 라벨 별 정답 cnt_list [41, 6, 4, 182, 985, 168, 23, 125]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjepMWfRsp6C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "6272f1db-77be-4f1b-a268-e5c93da486f2"
      },
      "source": [
        "target_names = ['anger', 'disgust', 'fear', 'joy', 'neutral', 'non-neutral', 'sadness', 'surprise']\r\n",
        "plt.bar(target_names,cnt_list)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 8 artists>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LzFXZcCsmXF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "outputId": "7294197a-df43-405c-c894-021a6278c5c4"
      },
      "source": [
        "matrix_evaluate(pred_list, true_list, cnt_list)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger     0.2547    0.4881    0.3347        84\n",
            "     disgust     0.0882    0.1250    0.1034        48\n",
            "        fear     0.1250    0.1212    0.1231        33\n",
            "         joy     0.5987    0.4727    0.5283       385\n",
            "     neutral     0.7653    0.7253    0.7448      1358\n",
            " non-neutral     0.3105    0.3105    0.3105       541\n",
            "     sadness     0.2706    0.3710    0.3129        62\n",
            "    surprise     0.4371    0.4941    0.4638       253\n",
            "\n",
            "    accuracy                         0.5550      2764\n",
            "   macro avg     0.3563    0.3885    0.3652      2764\n",
            "weighted avg     0.5770    0.5550    0.5632      2764\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAsMATmLsGJY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_GsRFFbhSwj"
      },
      "source": [
        "# test 결과물"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_S78N33ohWWl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ac22245-9400-443f-aad3-4ab90b3ed353"
      },
      "source": [
        "tmp_test_dataloader = DataLoader(test_df_data, sampler=test_df_sampler, batch_size=1)\r\n",
        "test_result = test_df.copy(deep = True)\r\n",
        "test_result = test_result.drop(columns = ['i_dialog', 'i_utterance', 'speaker'])\r\n",
        "test_result['Predicted'] = 'default'\r\n",
        "classes = [0,1,2,3,4,5,6,7]\r\n",
        "\r\n",
        "encoder = LabelEncoder()\r\n",
        "classes = emotions\r\n",
        "encoder.fit(classes)\r\n",
        "classes = encoder.transform(classes)\r\n",
        "\r\n",
        "#시작 시간 설정\r\n",
        "t0 = time.time()\r\n",
        "\r\n",
        "# 평가모드로 변경\r\n",
        "model.eval()\r\n",
        "\r\n",
        "# 변수 초기화\r\n",
        "nb_eval_steps, nb_eval_examples = 0, 0\r\n",
        "\r\n",
        "# 데이터로더에서 배치만큼 반복하여 가져옴\r\n",
        "for step, batch in enumerate(tmp_test_dataloader):\r\n",
        "    # 경과 정보 표시\r\n",
        "    if step % 100 == 0 and not step == 0:\r\n",
        "        elapsed = format_time(time.time() - t0)\r\n",
        "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(tmp_test_dataloader), elapsed))\r\n",
        "\r\n",
        "    # 배치를 GPU에 넣음\r\n",
        "    batch = tuple(t.to(device) for t in batch)\r\n",
        "    \r\n",
        "    # 배치에서 데이터 추출\r\n",
        "    b_index, b_input_ids, b_input_mask = batch\r\n",
        "    \r\n",
        "    # 그래디언트 계산 안함\r\n",
        "    with torch.no_grad():     \r\n",
        "        # Forward 수행\r\n",
        "        outputs = model(b_input_ids, \r\n",
        "                        token_type_ids=None, \r\n",
        "                        attention_mask=b_input_mask)\r\n",
        "    \r\n",
        "    # 로스 구함\r\n",
        "    logits = outputs[0]\r\n",
        "\r\n",
        "    # CPU로 데이터 이동\r\n",
        "    logits = logits.detach().cpu().numpy()\r\n",
        "    idx = b_index.item()\r\n",
        "    test_result['Predicted'][idx] = encoder.classes_[np.argmax(logits)]\r\n",
        "    \r\n",
        "\r\n",
        "    nb_eval_steps += 1\r\n",
        "\r\n",
        "print(\"\")\r\n",
        "print(\"Test took: {:}\".format(format_time(time.time() - t0)))\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:47: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch   100  of  1,623.    Elapsed: 0:00:01.\n",
            "  Batch   200  of  1,623.    Elapsed: 0:00:02.\n",
            "  Batch   300  of  1,623.    Elapsed: 0:00:04.\n",
            "  Batch   400  of  1,623.    Elapsed: 0:00:05.\n",
            "  Batch   500  of  1,623.    Elapsed: 0:00:06.\n",
            "  Batch   600  of  1,623.    Elapsed: 0:00:07.\n",
            "  Batch   700  of  1,623.    Elapsed: 0:00:09.\n",
            "  Batch   800  of  1,623.    Elapsed: 0:00:10.\n",
            "  Batch   900  of  1,623.    Elapsed: 0:00:11.\n",
            "  Batch 1,000  of  1,623.    Elapsed: 0:00:12.\n",
            "  Batch 1,100  of  1,623.    Elapsed: 0:00:13.\n",
            "  Batch 1,200  of  1,623.    Elapsed: 0:00:14.\n",
            "  Batch 1,300  of  1,623.    Elapsed: 0:00:16.\n",
            "  Batch 1,400  of  1,623.    Elapsed: 0:00:17.\n",
            "  Batch 1,500  of  1,623.    Elapsed: 0:00:18.\n",
            "  Batch 1,600  of  1,623.    Elapsed: 0:00:19.\n",
            "\n",
            "Test took: 0:00:19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtVGAJ3QhWY6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ccba89f-191e-433e-9aee-bf5636d6daf8"
      },
      "source": [
        "test_result['Predicted']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0           neutral\n",
              "1               joy\n",
              "2             anger\n",
              "3           neutral\n",
              "4       non-neutral\n",
              "           ...     \n",
              "1618        neutral\n",
              "1619            joy\n",
              "1620        neutral\n",
              "1621        neutral\n",
              "1622          anger\n",
              "Name: Predicted, Length: 1623, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PmG3cdAhWbk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "f7f7cb03-252f-49cf-a8c9-e85d3cb79b49"
      },
      "source": [
        "test_result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>utterance</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Alright, whadyou do with him?</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Oh! You're awake!</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Then you gotta come clean with Ma! This is not...</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Yeah, but this is</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>I don't wanna hear it! Now go to my room!</td>\n",
              "      <td>non-neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1618</th>\n",
              "      <td>1618</td>\n",
              "      <td>Nooo.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1619</th>\n",
              "      <td>1619</td>\n",
              "      <td>Hi, Kate!</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1620</th>\n",
              "      <td>1620</td>\n",
              "      <td>Hi, Lauren.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1621</th>\n",
              "      <td>1621</td>\n",
              "      <td>Hi, Lauren.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1622</th>\n",
              "      <td>1622</td>\n",
              "      <td>Hi, pig!</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1623 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        id                                          utterance    Predicted\n",
              "0        0                      Alright, whadyou do with him?      neutral\n",
              "1        1                                  Oh! You're awake!          joy\n",
              "2        2  Then you gotta come clean with Ma! This is not...        anger\n",
              "3        3                                  Yeah, but this is      neutral\n",
              "4        4          I don't wanna hear it! Now go to my room!  non-neutral\n",
              "...    ...                                                ...          ...\n",
              "1618  1618                                              Nooo.      neutral\n",
              "1619  1619                                          Hi, Kate!          joy\n",
              "1620  1620                                        Hi, Lauren.      neutral\n",
              "1621  1621                                        Hi, Lauren.      neutral\n",
              "1622  1622                                           Hi, pig!        anger\n",
              "\n",
              "[1623 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2qTHzzshGhq"
      },
      "source": [
        "test_result.drop(labels='utterance', axis=\"columns\", inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_lLlP__hacf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "6c07fb17-2d2f-405b-b038-663512b88260"
      },
      "source": [
        "test_csv = test_result.to_csv('submission_bert_uncase_20.csv', columns=['id', 'Predicted'], index=False)\r\n",
        "from google.colab import files\r\n",
        "\r\n",
        "files.download('submission_bert_uncase_20.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_7d694564-b55f-4b5a-8c53-65b1cb6d9270\", \"submission_bert_uncase_20.csv\", 20720)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}